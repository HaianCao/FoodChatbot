\documentclass[a4paper]{book}

% Packages
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage[utf8]{vietnam}
\usepackage{amsmath}
\usepackage{amssymb}

% Define degree symbol command to avoid undefined \degree
\newcommand{\degree}{\ensuremath{^\circ}}

% Geometry setup
\geometry{left=2cm,right=2cm,top=2cm,bottom=2cm}

% Titlepage information
\newcommand{\reporttitle}{Chatbot Ẩm Thực}
\newcommand{\reportauthors}{%
    Cao Hải An - 23001818 \\
    Đặng Thế Anh - 23001821 \\
    Phạm Minh Cương - 23001840 \\
    Đỗ Minh Đức - 23001864 \\
    Phạm Nhật Quang - 23001920
}
\newcommand{\courseinfo}{Mã học phần: MAT1207E \\ Học kỳ 1, Năm học 2025-2026}
\newcommand{\universitylogo}{HUS.png} % Đặt file logo vào cùng thư mục

\newcommand{\doi}[1]{\href{https://doi.org/#1}{\texttt{#1}}} % DOI link command

\begin{document}

% Trang bìa
\begin{titlepage}
    \centering
    \vspace*{-1cm}
    {\LARGE\MakeUppercase{Đại học Quốc gia Hà Nội}\par}
    {\LARGE\MakeUppercase{Trường Đại học Khoa học Tự nhiên}\par}
    \vfill
    \includegraphics[width=0.3\textwidth]{\universitylogo}\par\vfill
    {\Huge \bfseries \reporttitle \par}
    \vspace{1cm}
    {\Large \reportauthors \par}
    \vspace{1cm}
    {\large \courseinfo \par}
    \vfill
\end{titlepage}

% Trang thông tin dự án
\clearpage
\thispagestyle{empty}
\begin{center}
    {\LARGE \textbf{Thông tin Dự án}}\\[1.5em]
    \begin{tabular}{rl}
        \textbf{Học phần:} & MAT1207E -- Nhập môn Trí tuệ Nhân tạo \\
        \textbf{Học kỳ:} & Học kỳ 1, Năm học 2025-2026 \\
        \textbf{Trường:} & VNU-HUS (Đại học Quốc gia Hà Nội -- Trường Đại học Khoa học Tự nhiên) \\
        \textbf{Tên dự án:} & Chatbot Ẩm Thực \\
        \textbf{Ngày nộp:} & {[Ngày nộp]} (ví dụ: 30/06/2025) \\
        \textbf{Báo cáo PDF:} & \href{[PDF Link]}{Liên kết tới báo cáo PDF trong kho GitHub} \\
        \textbf{Slide thuyết trình:} & \href{[Slides Link]}{Liên kết tới slide thuyết trình trong kho GitHub} \\
        \textbf{Kho GitHub:} & \url{https://github.com/HaianCao/FoodChatbot}
    \end{tabular}
    \\[2em]
    {\Large \textbf{Thành viên nhóm}}\\[1em]
    \begin{tabular}{|l|l|l|l|}
        \hline
        \textbf{Họ tên} & \textbf{Mã sinh viên} & \textbf{Tên GitHub} & \textbf{Đóng góp} \\
        \hline
        Cao Hải An & 23001818 & HaianCao & Xây dựng pipeline chatbot \\
        \hline
        Đặng Thế Anh & 23001821 & DangTAnh & Thu thập dữ liệu \\
        \hline
        Phạm Minh Cương & 23001840 & mcnb2005 & Phát triển giao diện web \\
        \hline
        Đỗ Minh Đức & 23001864 & minhhhduc & Xây dựng module truy xuất dữ liệu \\
        \hline
        Phạm Nhật Quang & 23001920 & NhatquangPham & Tiền xử lý dữ liệu \\
        \hline
    \end{tabular}
\end{center}
\clearpage

\listoffigures % Remove if not needed

\listoftables % Remove if not needed

\tableofcontents
\clearpage

% Chương 1: Giới thiệu
\chapter{Giới thiệu}

\section{Tóm tắt}
Dự án xây dựng một hệ thống chatbot ẩm thực thông 
minh có khả năng cung cấp thông tin toàn diện về 
món ăn, bao gồm cách chế biến, thành phần nguyên 
liệu, giá trị dinh dưỡng và các gợi ý ẩm thực cá 
nhân hóa. Hệ thống được phát triển dựa trên kiến 
trúc Retrieval-Augmented Generation (RAG), kết hợp 
mô hình ngôn ngữ lớn Gemini và cơ sở dữ liệu 
vector để nâng cao khả năng truy xuất và tổng hợp 
tri thức. Dữ liệu ẩm thực được chuẩn hóa, mã hóa 
thành vector nhúng và lưu trữ trong cơ sở dữ liệu vector để đảm bảo việc tìm kiếm thông tin nhanh 
chóng và chính xác. Khi người dùng đặt câu hỏi, 
hệ thống tự động truy xuất các tài liệu liên quan 
và sử dụng Gemini LLM để tạo ra câu trả lời tự 
nhiên, mạch lạc và đáng tin cậy. Kết quả cho 
thấy chatbot có khả năng hiểu ngữ cảnh tốt, hỗ 
trợ người dùng lựa chọn món ăn, gợi ý công thức 
dựa trên nguyên liệu sẵn có và cung cấp thông tin 
dinh dưỡng theo cách thân thiện và dễ sử dụng. Dự 
án là minh chứng cho việc kết hợp RAG và LLM trong 
việc xây dựng các hệ thống tư vấn thông minh trong 
lĩnh vực ẩm thực.

\section{Bài toán đặt ra}
Trong bối cảnh công nghệ số phát triển mạnh mẽ, 
thói quen tiếp cận thông tin của con người đã 
thay đổi đáng kể. Người dùng ngày càng có xu hướng 
tìm kiếm giải pháp nhanh, chính xác và mang tính 
cá nhân hóa cho các nhu cầu hằng ngày, trong đó 
việc lựa chọn món ăn và tìm kiếm công thức nấu 
nướng là những nhu cầu phổ biến nhất. Mặc dù nguồn 
thông tin ẩm thực trên Internet vô cùng phong phú, 
người dùng vẫn gặp nhiều khó khăn do dữ liệu bị 
phân tán, chất lượng không đồng đều và không phải 
lúc nào cũng phù hợp với điều kiện thực tế. Điều 
này đặt ra nhu cầu cần có một hệ thống trợ lý ảo 
có khả năng cung cấp thông tin ẩm thực đáng tin 
cậy, rõ ràng và được cá nhân hóa.

\subsection{Khả năng hiểu ngôn ngữ tự nhiên trong bối cảnh ẩm thực}

Người dùng có thể đưa ra những câu hỏi rất đa 
dạng, từ đơn giản như “Làm mì Ý thế nào?” đến phức 
tạp như “Tôi có gà, nấm và phô mai – có thể nấu 
món gì dưới 30 phút và ít calo?”. Do đó, hệ thống 
cần có khả năng phân tích ý định, nhận diện thực 
thể như nguyên liệu, món ăn, phương pháp chế biến, 
đồng thời hiểu rõ ngữ cảnh của câu hỏi. Bài toán 
đặt ra là tận dụng sức mạnh của mô hình ngôn ngữ 
lớn (LLM) để xử lý ngôn ngữ tự nhiên một cách 
linh hoạt và chính xác trong lĩnh vực ẩm thực.

\subsection{Khả năng truy xuất tri thức chính xác và nhanh chóng}

Kho tri thức ẩm thực rất rộng và bao gồm nhiều 
loại thông tin như nguyên liệu, dinh dưỡng, cách 
chế biến, các biến thể của món ăn và kỹ thuật 
nấu nướng. Hệ thống cần tổ chức và chuẩn hóa dữ 
liệu theo dạng có thể tìm kiếm hiệu quả. Việc sử 
dụng cơ sở dữ liệu vector (vector database) cho 
phép truy vấn dựa trên độ tương đồng ngữ nghĩa 
thay vì tìm kiếm từ khóa truyền thống.

Thách thức kỹ thuật bao gồm:
\begin{itemize}
    \item Chuẩn hóa và làm sạch dữ liệu không đồng 
    nhất.
    \item Mã hóa tri thức bằng các vector 
    nhúng có chất lượng cao.
    \item Thiết kế cơ chế truy vấn tối ưu nhằm 
    đảm bảo kết quả trả về chính xác và phù hợp 
    nhất với truy vấn.
\end{itemize}

\subsection{Sinh câu trả lời tự nhiên, mạch lạc và đáng tin cậy}

Không chỉ đơn thuần truy xuất thông tin, chatbot 
phải tạo ra câu trả lời mạch lạc và hữu ích. Điều 
này bao gồm hướng dẫn nấu ăn theo từng bước rõ 
ràng, giải thích lý do sử dụng nguyên liệu hoặc 
kỹ thuật cụ thể, phân tích khẩu vị, mức độ khó, 
thời gian chế biến, dinh dưỡng, cũng như đề xuất 
điều chỉnh món ăn theo nhu cầu sức khỏe của người 
dùng.

Việc kết hợp kiến trúc Retrieval-Augmented 
Generation (RAG) và mô hình Gemini LLM đảm bảo 
rằng câu trả lời vừa dựa trên tri thức chính 
xác vừa có tính tự nhiên và dễ hiểu.

\subsection{Cá nhân hóa theo nhu cầu và ràng buộc thực tế của người dùng}

Một hệ thống chatbot thông minh cần cung cấp gợi 
ý phù hợp với từng cá nhân, bao gồm:
\begin{itemize}
    \item Sở thích cá nhân như mức độ cay, khẩu 
    vị hoặc phong cách ẩm thực.
    \item Các chế độ dinh dưỡng đặc thù (ăn chay, 
    keto, low-carb, không gluten).
    \item Dị ứng hoặc hạn chế trong ăn uống.
    \item Nguyên liệu hiện có trong bếp.
    \item Mục tiêu sức khỏe (giảm cân, tăng cơ 
    hoặc giảm đường).
\end{itemize}

Do đó, bài toán đặt ra là tích hợp dữ liệu hồ sơ 
người dùng vào pipeline của hệ thống để tối ưu hóa 
khả năng cá nhân hóa trong từng câu trả lời.

\subsection{Ý nghĩa thực tiễn và tác động}

Khi giải quyết tốt các yêu cầu trên, hệ thống 
chatbot ẩm thực mang đến nhiều giá trị thực tiễn:
\begin{itemize}
    \item Giảm thời gian tìm kiếm và tổng hợp 
    thông tin từ nhiều nguồn.
    \item Hỗ trợ người dùng trong quá trình nấu 
    ăn với các hướng dẫn trực quan.
    \item Khuyến khích khám phá các món ăn mới 
    phù hợp với khẩu vị cá nhân.
    \item Cung cấp thông tin dinh dưỡng một cách 
    rõ ràng và chính xác.
    \item Mang lại trải nghiệm nấu nướng tiện lợi 
    và hiệu quả hơn nhờ sự hỗ trợ của AI.
\end{itemize}

Dự án cũng minh chứng cho khả năng ứng dụng của 
các mô hình LLM kết hợp RAG trong việc phát triển 
hệ thống tư vấn thông minh trong lĩnh vực ẩm 
thực, giải quyết hiệu quả bài toán truy xuất 
tri thức không cấu trúc quy mô lớn.

% Chương 2: Phương pháp & Triển khai
\chapter{Phương pháp \& Triển khai}

\section{Phương pháp}

Dự án chatbot ẩm thực được xây dựng dựa trên sự 
kết hợp giữa mô hình ngôn ngữ lớn (Large Language 
Model -- LLM), kiến trúc Retrieval-Augmented 
Generation (RAG) và cơ sở dữ liệu vector nhằm 
tối ưu hóa khả năng truy xuất tri thức ẩm thực 
cũng như sinh phản hồi tự nhiên, chính xác và 
đáng tin cậy. Phần này trình bày chi tiết cách 
tiếp cận tổng thể, cơ sở lý thuyết, kiến trúc 
thành phần, thuật toán chính và dữ liệu sử dụng 
trong hệ thống.

\subsection{Cách tiếp cận}

Cách tiếp cận tổng thể của dự án dựa trên nguyên 
tắc: kết hợp sức mạnh sinh ngôn ngữ của LLM 
với khả năng tìm kiếm tri thức theo ngữ nghĩa 
của cơ sở dữ liệu vector. Điều này giúp hệ 
thống khắc phục hạn chế về tính cập nhật của 
mô hình ngôn ngữ đơn thuần tức không thể tự động 
biết thông tin mới sau thời điểm chúng được huấn 
luyện, đồng thời duy trì 
chất lượng ngôn ngữ tự nhiên và khả năng gợi ý 
chính xác theo bối cảnh. Hệ thống được triển 
khai theo pipeline RAG tiêu chuẩn với các bước 
chi tiết như sau:

\begin{itemize}
    \item \textbf{Kết hợp LLM và RAG}: Mô hình 
    LLM (Google Gemini) được sử dụng để xử lý 
    truy vấn đầu vào của người dùng với khả năng 
    hỗ trợ đa ngôn ngữ. Hệ thống chuyển đổi truy 
    vấn sang tiếng Anh nhằm tối ưu hóa quá trình 
    tìm kiếm trong cơ sở dữ liệu và đảm bảo tính 
    nhất quán trong biểu diễn văn bản. Sau khi 
    truy xuất được các ngữ cảnh phù hợp, LLM 
    tiếp tục sinh phản hồi bằng tiếng Anh sau đó
    phản hồi này được dịch lại sang chính ngôn ngữ 
    ban đầu của người dùng. Kiến trúc RAG đóng 
    vai trò bổ sung tri thức từ kho dữ liệu được 
    tổ chức dưới dạng vector, giúp hệ thống nâng 
    cao độ chính xác và tính tin cậy của câu trả 
    lời so với việc chỉ sử dụng LLM đơn thuần.

    \item \textbf{Thu thập dữ liệu ẩm thực}: Dữ 
    liệu được lấy từ trang web nấu ăn uy tín 
    thông qua hệ thống khai thác dữ liệu. Bộ dữ liệu bao 
    gồm thông tin chi tiết về tên món ăn, mô tả sơ lược, \
    thành phần nguyên liệu,
    hướng dẫn nấu theo từng bước, thời gian chế 
    biến, khẩu phần, giá trị dinh dưỡng.
    
    \item \textbf{Tiền xử lý và chuẩn hóa dữ liệu}: 
    Dữ liệu thu thập thường chứa nhiều nhiễu, sai 
    sót về chính tả hoặc về cách biểu diễn số học, 
    và không đồng nhất về đơn vị. Do đó, hệ thống 
    áp dụng các bước xử lý chuẩn hóa unicode, thay 
    thế ký tự đặc biệt, chuẩn hóa phân số, thời gian, 
    tách số và đơn vị, tách bình luận và tên,... Các đặc 
    trưng quan trọng được trích xuất để phục vụ 
    cho việc embedding và truy xuất dữ liệu.
    
    \item \textbf{Sinh vector nhúng}: Văn bản 
    sau khi được chuẩn hóa được đưa vào mô hình 
    nhúng từ để chuyển đổi thành vector biểu 
    diễn tương ứng. Các vector này mã hóa thông 
    tin ngữ nghĩa của món ăn giúp hệ thống có thể 
    truy vấn hiệu quả theo nghĩa (semantic search) 
    thay vì chỉ tìm kiếm theo từ khóa.
    
    \item \textbf{Lưu trữ tri thức vào cơ sở 
    dữ liệu vector}: Các vector nhúng cùng 
    với metadata được lưu trữ trong ChromaDB. 
    Cơ sở dữ liệu vector cho phép hệ thống thực 
    hiện tìm kiếm dựa trên độ tương đồng cosine, 
    tối ưu cho các truy vấn phức tạp liên quan 
    đến ngữ cảnh và ý định người dùng.
    
    \item \textbf{Tìm kiếm ngữ nghĩa}: Khi người 
    dùng đưa ra câu hỏi, hệ thống sinh vector nhúng 
    cho truy vấn, sau đó truy xuất các vector 
    gần nhất trong không gian nhúng. Các 
    tài liệu liên quan nhất được lựa chọn và 
    ghép vào ngữ cảnh đầu vào cho mô hình LLM.
    
    \item \textbf{Tổng hợp và sinh phản hồi}: 
    LLM Gemini sử dụng ngữ cảnh từ bước truy 
    xuất để sinh phản hồi mạch lạc, đầy đủ và 
    chính xác. Nhờ cơ chế này, hệ thống vừa đảm 
    bảo tính thực tiễn của tri thức ẩm thực, vừa 
    duy trì khả năng diễn đạt tự nhiên và tùy 
    biến theo nhu cầu người dùng.
\end{itemize}

Với pipeline RAG, dự án chatbot ẩm thực đạt được 
sự cân bằng giữa khả năng sinh ngôn ngữ tự nhiên 
của LLM và độ chính xác trong cung cấp tri thức 
thực tế. Điều này cho phép chatbot không chỉ trả 
lời câu hỏi về công thức nấu ăn, nguyên liệu hay 
dinh dưỡng, mà còn đưa ra gợi ý tùy chỉnh theo 
sở thích cá nhân, hạn chế ăn uống hoặc nguyên 
liệu có sẵn của người dùng.

\subsection{Cơ sở lý thuyết}

\subsubsection{Mô hình ngôn ngữ lớn (Large 
Language Model -- LLM)}

Hệ thống sử dụng mô hình Gemini, thuộc họ các 
mô hình ngôn ngữ lớn (LLM) hiện đại, được huấn 
luyện trên tập dữ liệu văn bản đa dạng và quy 
mô lớn. Về mặt kiến trúc, Gemini (tương tự các 
LLM hiện đại khác) được xây dựng dựa trên 
Transformer nhiều tầng.

\paragraph{Kiến trúc Transformer}
Transformer được mô tả rất rõ ràng trong 
\cite{transformer} gồm các lớp xếp chồng (stacked 
layers), mỗi lớp bao gồm hai thành phần 
chính: cơ chế Self-Attention và 
mạng Feed-Forward vị trí-tách rời 
(position-wise feed-forward). Ở cấp độ token, 
đầu vào là một chuỗi token 
\(x_1, x_2, \dots, x_n\) được ánh xạ thành 
embedding \(E = [e_1, \dots, e_n]\).

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth]{Transformer.png}
    \caption{Kiến trúc mô hình Transformer.\cite{transformer}}
\end{figure}
\paragraph{Self-Attention}
Cho một lớp attention đơn, với ma trận trọng 
số \(W_Q, W_K, W_V\) chuyển embedding thành 
các vectors Query \(Q\), Key \(K\) và Value \(V\):
\[
Q = E W_Q,\quad K = E W_K,\quad V = E W_V.
\]
Điểm attention giữa token i và token j được tính 
bằng:
\[
\text{score}(i,j) = \frac{q_i \cdot k_j}{\sqrt{d_k}},
\]
sau đó áp dụng softmax để có trọng số attention:
\[
\alpha_{ij} = \frac{\exp(\text{score}(i,j))}{\sum_{t=1}^n \exp(\text{score}(i,t))}.
\]
Biểu diễn đầu ra cho token i là tổng có trọng 
số các value:
\[
z_i = \sum_{j=1}^n \alpha_{ij} v_j.
\]
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\textwidth]{self_attention.png}
    \caption{Cơ chế Self-Attention.\cite{self_attention}}
\end{figure}

\textbf{Multi-head attention} tách không gian 
biểu diễn thành nhiều head độc lập, cho phép mô 
hình học nhiều loại quan hệ khác nhau giữa token.
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\textwidth]{multihead_attention.png}
    \caption{Cơ chế Multi-Head Attention.\cite{multihead_attention}}
\end{figure}

\paragraph{Feed-Forward Layers}
Sau attention, mỗi token đi qua một mạng 
feed-forward theo từng vị trí:
\[
\text{FFN}(x) = \text{ReLU}(x W_1 + b_1) W_2 + b_2.
\]
Các lớp này tạo ra biểu diễn phi tuyến mạnh hơn 
cho từng token.

\paragraph{Layer Normalization \& Residual Connection}

Trong mỗi tầng con của Transformer (self–attention hoặc feed–forward), đầu vào $x$ được xử lý qua hai cơ chế quan trọng: \textit{residual connection} và \textit{layer normalization}. Hai cơ chế này giúp ổn định gradient, duy trì thông tin gốc và tăng tốc độ hội tụ của mô hình.

\subparagraph{Residual Connection}

Cho đầu vào của sub-layer là $x$ và phép biến đổi của sub-layer là $\mathrm{SubLayer}(x)$.  
Residual connection được định nghĩa:

\[
h = x + \mathrm{SubLayer}(x).
\]

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.6\textwidth]{residual_connection.png}
    \caption{Cơ chế Residual Connection.\cite{nlp_book}}
\end{figure}

Cơ chế này đảm bảo rằng thông tin ban đầu vẫn được giữ lại, đồng thời giúp giảm hiện tượng mất mát gradient (vanishing gradient).

\subparagraph{Layer Normalization}

Sau khi tạo ra $h$, ta chuẩn hoá từng vector theo chiều ẩn.  
Giả sử $h = (h_1, h_2, \dots, h_d)$ với $d$ là kích thước embedding.

Trung bình và phương sai theo từng vector được tính như sau:

\[
\mu = \frac{1}{d} \sum_{i=1}^{d} h_i,
\qquad
\sigma^2 = \frac{1}{d} \sum_{i=1}^{d} (h_i - \mu)^2.
\]

Layer Normalization được áp dụng cho từng phần tử:

\[
\mathrm{LayerNorm}(h)_i
= 
\gamma \cdot 
\frac{h_i - \mu}{\sqrt{\sigma^2 + \epsilon}} 
+ \beta,
\]

trong đó $\gamma$ và $\beta$ là các tham số học được, và $\epsilon$ đảm bảo ổn định số học.

\subparagraph{Công thức tổng quát của Transformer Block}

Residual và Layer Normalization được gộp lại thành:

\[
\mathrm{Output}
=
\mathrm{LayerNorm}\!\left(
x + \mathrm{SubLayer}(x)
\right).
\]

Khai triển đầy đủ theo từng phần tử:

\[
\mathrm{Output}_i
=
\gamma \cdot
\frac{
\left[x_i + \mathrm{SubLayer}(x)_i\right] - \mu
}{
\sqrt{\sigma^2 + \epsilon}
}
+ \beta,
\]

với:

\[
\mu
=
\frac{1}{d}
\sum_{j=1}^{d}
\left(x_j + \mathrm{SubLayer}(x)_j\right),
\quad
\sigma^2
=
\frac{1}{d}
\sum_{j=1}^{d}
\left[
\left(x_j + \mathrm{SubLayer}(x)_j\right) - \mu
\right]^2.
\]

Transformer nhiều tầng cho phép mô hình nắm bắt 
quan hệ ngữ cảnh dài hạn, suy luận phức tạp và 
sinh ngôn ngữ tự nhiên chất lượng cao — những 
yếu tố cần thiết cho việc hiểu truy vấn ẩm thực 
phức tạp và sinh hướng dẫn nấu ăn.

\paragraph{Tính năng đa ngôn ngữ và tiền xử lý truy vấn}
Trong dự án, Gemini được khai thác với khả năng 
đa ngôn ngữ: hệ thống có thể tiền xử lý truy vấn 
đầu vào (chẳng hạn dịch sang tiếng Anh để tương 
thích tốt hơn với vector DB / vector nhúng được 
thống nhất), sau đó sinh phản hồi bằng ngôn ngữ 
người dùng. Việc này tối ưu hóa độ tương đồng 
ngữ nghĩa khi nhúng và truy xuất.

\paragraph{Cải tiến kiến trúc trong Gemini 2.5 Flash-Lite\cite{gemini_2.5}}
Khác với kiến trúc Transformer 
tiêu chuẩn (Dense Transformer) nêu trên, mô hình 
Gemini 2.5 Flash-Lite tích hợp các kỹ thuật tối 
ưu hóa hiện đại nhằm cân bằng giữa hiệu năng tính 
toán và khả năng suy luận, đặc biệt phù 
hợp cho các hệ thống yêu cầu độ trễ thấp:

\textbf{1. Mixture-of-Experts (MoE) thưa\cite{gemini_1.5}:} 
Thay vì kích hoạt toàn bộ tham số mạng cho mỗi 
token, hệ thống sử dụng kiến trúc MoE thưa 
(Sparse MoE). Mỗi lớp Feed-Forward bao gồm tập 
hợp các "chuyên gia" (experts) 
$\{E_1, \dots, E_N\}$. Một mạng Gating 
$G(x)$ sẽ chọn ra top-k chuyên gia phù hợp 
nhất cho đầu vào $x$:
\[
y = \sum_{i \in \text{Top-k}(G(x))} G(x)_i \cdot E_i(x).
\]
Điều này giúp giảm chi phí tính toán tuyến tính 
trong khi vẫn duy trì dung lượng bộ nhớ 
(capacity) của một mô hình lớn.

\textbf{2. Grouped-Query Attention (GQA)\cite{gqa}:} 
Để tối ưu hóa bộ nhớ KV-Cache trong quá trình 
suy luận (inference), mô hình thay thế 
Multi-Head Attention truyền thống bằng 
Grouped-Query Attention. Số lượng đầu Key 
($H_K$) và Value ($H_V$) ít hơn số lượng đầu 
Query ($H_Q$) theo tỷ lệ $G = H_Q / H_K$. 
Điều này giảm băng thông bộ nhớ cần thiết để 
tải các ma trận $K, V$:
\[
\text{GQA}(Q, K, V) = \text{Concat}(\text{head}_1, \dots, \text{head}_{H_Q}) W_O,
\]
trong đó mỗi nhóm $G$ queries chia sẻ chung một cặp đầu $k, v$.

\textbf{3. Rotary Positional Embeddings (RoPE):} 
Thay vì cộng vector vị trí tuyệt đối, Gemini 
sử dụng mã hóa vị trí quay (RoPE) để bảo toàn 
tốt hơn tính chất khoảng cách tương đối giữa 
các token. Với vector $x$ tại vị trí $m$, phép 
biến đổi được thực hiện bằng phép quay trong 
không gian phức:
\[
f(x, m) = (x_1, x_2, \dots, x_d) \otimes (\cos m\theta, \cos m\theta, \dots),
\]
kết hợp với thành phần ảo để xoay vector, cho 
phép mô hình ngoại suy tốt hơn trên các ngữ cảnh 
dài (long-context extrapolation).

\textbf{4. Hàm kích hoạt và Chuẩn hóa:} 
Cải thiện tính ổn định hội tụ bằng cách thay 
thế LayerNorm truyền thống bằng \textbf{RMSNorm} 
(Root Mean Square Normalization) và sử dụng 
hàm kích hoạt \textbf{SwiGLU} thay cho ReLU 
trong các khối FFN:
\[
\text{RMSNorm}(x) = \frac{x}{\sqrt{\frac{1}{d} \sum_{i=1}^d x_i^2 + \epsilon}} \cdot \gamma,
\]
\[
\text{SwiGLU}(x, W, V, W_2) = (\text{Swish}(xW) \otimes (xV)) W_2.
\]

\subsubsection{Vector Database và Nhúng từ}

\paragraph{Ý tưởng nhúng từ}
Nhúng từ là hàm ánh xạ \(f: \text{Text} \to 
\mathbb{R}^d\) đưa một đoạn văn bản (ví dụ: 
tên món, danh sách nguyên liệu, bước nấu) về 
không gian vector \(d\)-chiều sao cho các văn 
bản có ý nghĩa tương tự nằm gần nhau. ChromaDB cung cấp pipeline để 
sinh nhúng từ cho từng văn bản và lưu trữ 
chúng cùng metadata.

\paragraph{Cách cấu trúc dữ liệu}
Mỗi mục trong database gồm:
\begin{itemize}
    \item \texttt{ids}: Khóa duy nhất cho mỗi document.
    \item \texttt{embeddings}: Vectơ \(\in 
    \mathbb{R}^d\).
    \item \texttt{documents}: Nội dung văn bản thô 
    (ví dụ: "Ingredients: ...; Steps: ...").
    \item \texttt{metadatas}: Metadata bổ sung 
    (ví dụ: tên món, thời gian nấu, dinh dưỡng,...).
\end{itemize}

\paragraph{Ưu điểm của vector DB}
\begin{itemize}
    \item \textbf{Tìm kiếm ngữ nghĩa}: truy 
    vấn không phụ thuộc vào từ khóa chính xác.
    \item \textbf{Khả năng mở rộng}: lưu trữ 
    hàng chục ngàn đến hàng triệu vectors, kết 
    hợp ANN (Approximate Nearest Neighbor Search 
    - Tìm kiếm láng giềng gần đúng) để truy vấn hiệu quả.
    \item \textbf{Dễ cập nhật tri thức}: chỉ 
    cần thêm/sửa văn bản mà không phải fine-tune 
    LLM.
\end{itemize}

\subsubsection{Cosine Similarity và các chỉ số 
đánh giá tương đồng}

\paragraph{Định nghĩa cosine similarity\cite{nlp_book}}
Với hai vector \(u, v \in \mathbb{R}^d\), độ 
tương đồng cosine được tính:
\[
\text{cosine}(u,v) = \frac{u \cdot v}{\|u\| \cdot \|v\|} = \frac{\sum_{i=1}^d u_i v_i}{\sqrt{\sum_{i=1}^d u_i^2} \cdot \sqrt{\sum_{i=1}^d v_i^2}} 
\]
Mục tiêu là chọn những văn bản có cosine cao 
nhất so với vector nhúng của truy vấn.

\paragraph{Thuộc tính và ngưỡng}
\begin{itemize}
    \item Giá trị nằm trong \([-1,1]\), nhưng 
    với nhúng từ từ LLM/public models thường 
    nằm trong \([0,1]\) do cấu trúc nhúng.
    \item Thực tiễn: đặt ngưỡng lọc (ví dụ 
    0.65–0.75) để loại bỏ văn bản không liên 
    quan; ngưỡng cụ thể cần hiệu chỉnh dựa trên 
    đánh giá thực nghiệm.
    \item Kết hợp với ranking dựa trên cosine 
    để chọn top-\(k\) văn bản (k thường trong 
    khoảng 3–10).
\end{itemize}

\subsubsection{Kiến trúc Retrieval-Augmented 
Generation (RAG)\cite{nlp_book}}

\paragraph{Nguyên lý tổng quát}

RAG là một kiến trúc lai giữa khả năng 
hiểu và sinh ngôn ngữ của LLM và khả 
năng truy xuất tri thức chính xác của 
cơ sở dữ liệu dạng vector. Khi người dùng đưa 
ra một câu hỏi, hệ thống không để mô hình LLM 
tự trả lời dựa trên trí nhớ nội tại, mà thay vào đó:
\begin{enumerate}
    \item Truy xuất tri thức liên quan một cách 
    có kiểm soát từ kho dữ liệu ẩm thực.
    \item Kết hợp tri thức đó vào prompt để 
    LLM sinh ra câu trả lời dựa trên thông 
    tin có thật.
\end{enumerate}

Cách tiếp cận này tối ưu cho các bài toán yêu 
cầu thông tin cập nhật, chính xác, giảm thiểu sai 
sót do mô hình tự bịa (hallucination).

\paragraph{Hệ thống gồm 2 mô-đun chính}
\begin{enumerate}
    \item \textbf{Retriever}: nhận câu hỏi, sinh 
    embedding, so khớp với các vector trong 
    database và trả về các đoạn văn bản liên 
    quan nhất.
    \item \textbf{Generator}: dùng mô hình 
    LLM để sinh câu trả lời dựa trên ngữ cảnh 
    đã được truy xuất.
\end{enumerate}

Hai mô-đun hoạt động độc lập nhưng liên kết chặt 
chẽ, đảm bảo luồng xử lý rõ ràng và dễ mở rộng.

\paragraph{Lợi ích nổi bật của RAG}
\begin{itemize}
    \item \textbf{Giảm hallucination}: LLM phải 
    dựa trên các đoạn ngữ cảnh có thật, giúp hạn 
    chế sinh thông tin sai.
    \item \textbf{Không cần huấn luyện lại LLM}: 
    chỉ việc cập nhật vector DB là hệ thống có 
    thêm tri thức mới.
    \item \textbf{Tùy biến theo mục tiêu}: có 
    thể thay đổi chiến lược truy xuất (top-$k$, 
    filter theo tag nguyên liệu, theo calories, 
    \dots), hoặc tùy chỉnh quy tắc tạo prompt.
\end{itemize}

\paragraph{Chi tiết prompt injection}
Thực tế thường áp dụng chiến lược:
\begin{enumerate}
    \item Lấy top-\(k\) đoạn liên quan.
    \item Nếu các đoạn dài, tóm tắt mỗi đoạn 
    bằng một sentence ngắn (summary) trước khi 
    chèn vào prompt.
    \item Chèn metadata quan trọng (ví dụ: 
    nguồn, thời gian nấu, lượng calo).
    \item Cấu trúc prompt: \texttt{[System 
    Instruction] + [Retrieved Contexts] + 
    [User Query]}.
\end{enumerate}

\subsection{Thuật toán tổng quát}

Thuật toán chính của hệ thống được thiết kế xoay 
quanh pipeline Retrieval-Augmented Generation (RAG), 
kết hợp giữa khả năng suy luận ngôn ngữ của mô hình 
Gemini và khả năng truy xuất tri thức theo ngữ nghĩa 
từ ChromaDB. Pipeline thuật toán gồm các bước sau:

\subsubsection{1. Nhận và chuẩn hoá truy vấn người dùng}

\begin{itemize}
    \item Người dùng gửi câu hỏi bất kỳ liên quan 
    đến món ăn, nguyên liệu hoặc gợi ý nấu nướng.
    \item Truy vấn được đưa vào mô-đun sử dụng 
    Gemini để đảm nhiệm việc:
    \begin{itemize}
        \item Phát hiện ngôn ngữ đầu vào.
        \item Dịch truy vấn sang tiếng Anh nếu cần 
        (để tương thích với dữ liệu embedding 
        trong DB).
        \item Chuẩn hóa và loại bỏ nhiễu trong 
        câu hỏi.
    \end{itemize}
\end{itemize}

\subsubsection{2. Sinh embedding cho truy vấn}
\begin{itemize}
    \item Truy vấn tiếng Anh sẽ được đưa qua API 
    embedding của ChromaDB:
    \[
        q = \text{Embed}(query)
    \]
    \item Kết quả là vector biểu diễn độ dài cố 
    định dùng để truy vấn vào cơ sở dữ liệu vector.
\end{itemize}

\subsubsection{3. Truy vấn ngữ nghĩa (Semantic Retrieval)}
\begin{itemize}
    \item ChromaDB lưu các embedding của tài liệu 
    ẩm thực.
    \item Hệ thống thực hiện tìm kiếm top-$k$ 
    đoạn gần nhất:
    \[
        \text{docs} = \text{ChromaDB.top\_k}(q, k)
    \]
    \item Độ tương đồng được tính bằng cosine 
    similarity:
    \[
        \text{sim}(q, d_i) = \frac{q \cdot d_i}{\|q\|\|d_i\|}
    \]
    \item Các đoạn văn liên quan nhất được trả 
    về kèm metadata: tên món, nguyên liệu, thời 
    gian nấu, mô tả, v.v.
\end{itemize}

\subsubsection{4. Tiêm ngữ cảnh (Context Injection)}
\begin{itemize}
    \item Các đoạn thu được được tổng hợp lại 
    thành một khối văn bản dạng:
    \[
        C = \text{concat}(d_1, d_2, \ldots, d_k)
    \]
    \item Context được chèn vào prompt theo 
    cấu trúc:
    \[
        P = [System\ Instructions] + [Retrieved\ Context\ C] + [User\ Query]
    \]
    \item Đây là giai đoạn quan trọng đảm bảo 
    Gemini không sinh thông tin sai (hallucination).
\end{itemize}

\subsubsection{5. Sinh phản hồi (Answer Generation)}
\begin{itemize}
    \item Prompt hoàn chỉnh được gửi vào mô hình 
    Gemini.
    \item Gemini sinh câu trả lời bằng ngôn ngữ 
    tự nhiên tiếng Anh, sau khi:
    \begin{itemize}
        \item Kết hợp tri thức từ context đã 
        truy xuất.
        \item Giữ đúng ngôn ngữ đầu vào của 
        người dùng.
        \item Tối ưu nội dung theo hướng hội 
        thoại và hữu ích.
    \end{itemize}
    \item Đầu ra sau đó được dịch ngược trở lại
    đúng ngôn ngữ của người dùng nếu cần.
\end{itemize}

\subsubsection{6. Pipeline tổng thể}

\begin{enumerate}
    \item Nhận câu hỏi $Q$.
    \item Chuẩn hoá và dịch về tiếng Anh: 
    \[
        Q' = \text{Normalize}(Q)
    \]
    \item Sinh embedding truy vấn: 
    \[
        v = \text{Embed}(Q')
    \]
    \item Truy xuất top-$k$ đoạn liên quan: 
    \[
        D = \text{Retrieve}(v, k)
    \]
    \item Ghép ngữ cảnh: 
    \[
        P = \text{ConstructPrompt}(D, Q)
    \]
    \item Gửi prompt vào Gemini: 
    \[
        A = \text{Gemini.generate}(P)
    \]
    \item Nếu ngôn ngữ đầu vào không phải 
    tiếng Anh, dịch phản hồi về ngôn ngữ gốc.
    \[
        A' = \text{Translate}(A, \text{lang}(Q))
    \]
    \item Trả về phản hồi $A'$ cho người dùng.
\end{enumerate}


\subsection{Dữ liệu sử dụng}

Dữ liệu cho hệ thống chatbot ẩm thực được thu 
thập trực tiếp từ trang web 
\texttt{https://therecipecritic.com} thông qua 
quá trình khai thác tự động. Mỗi trang công thức 
nấu ăn được tách và lưu trữ dưới dạng một tệp 
JSON chứa đầy đủ các thành phần thông tin cần 
thiết phục vụ cho bước trích xuất tri thức và 
tạo nhúng từ.

\subsubsection{Cấu trúc dữ liệu thô}

Mỗi công thức sau khi khai thác được biểu diễn 
dưới dạng một đối tượng JSON có cấu trúc thống 
nhất như sau:

\begin{itemize}
    \item \textbf{URL}: đường dẫn tuyệt đối đến 
    trang công thức gốc.
    \item \textbf{Summary}: đoạn mô tả ngắn gọn 
    về món ăn, thường do tác giả cung cấp.
    \item \textbf{Metadata}: tập hợp thông tin 
    định lượng như thời gian sơ chế, thời gian 
    nấu, tổng thời gian và số khẩu phần.
    \item \textbf{Ingredients}: danh sách nguyên 
    liệu cần thiết, mỗi mục là một chuỗi mô tả 
    đầy đủ định lượng và tên nguyên liệu.
    \item \textbf{Instructions}: chuỗi các bước 
    hướng dẫn nấu ăn theo thứ tự.
    \item \textbf{Nutrition}: thông tin dinh 
    dưỡng cho mỗi khẩu phần (calories, fat, 
    protein, v.v.).
    \item \textbf{Comments}: các bình luận từ 
    người dùng thật, giúp chatbot có thêm dữ 
    liệu phản ánh trải nghiệm thực tế.
\end{itemize}

\subsubsection{Lưu trữ và tiền xử lý}

Sau khi dữ liệu thô được thu thập từ các trang 
công thức, hệ thống thực hiện một quy trình 
tiền xử lý nhằm chuẩn hóa và làm sạch dữ liệu, 
đảm bảo tính nhất quán và phù hợp cho các hệ 
thống RAG:

\begin{itemize}
    \item \textbf{Đọc và hợp nhất dữ liệu:} Tất 
    cả các tệp JSON trong file \texttt{.zip} 
    được đọc và hợp nhất, bỏ qua các tệp không 
    hợp lệ hoặc bị lỗi.
    
    \item \textbf{Chuẩn hóa văn bản:} Các trường 
    văn bản như URL, tóm tắt, nguyên liệu, 
    hướng dẫn được chuẩn hóa Unicode, loại bỏ 
    ký tự đặc biệt, khoảng trắng thừa, và các 
    biểu tượng không cần thiết. Các ký tự đặc 
    biệt và phân số Unicode được thay thế bằng 
    dạng chuẩn.
    
    \item \textbf{Chuẩn hóa dữ liệu định lượng:} 
    Các trường metadata (thời gian, khẩu phần) 
    và dinh dưỡng được chuẩn hóa về dạng số và 
    đơn vị chung (ví dụ phút, kcal). Regex và 
    các quy tắc parsing được áp dụng để tách số, 
    đơn vị và tên trường.
    
    \item \textbf{Tiền xử lý bình luận:} Các 
    bình luận được lọc để loại bỏ rỗng, spam 
    hoặc ký tự lỗi. Đồng thời, tách tác giả 
    khỏi nội dung bình luận (nếu có) và chuẩn 
    hóa văn bản, giữ lại thông tin quan trọng.
    
    \item \textbf{Chuẩn hóa cấu trúc dữ liệu:} 
    Mọi danh sách và dictionary đều được chuẩn 
    hóa, bảo đảm định dạng đồng nhất cho 
    nhúng từ và đánh chỉ số.
    
    \item \textbf{Lưu trữ dữ liệu cuối:} Dữ 
    liệu đã xử lý được hợp nhất thành một tệp 
    JSON duy nhất, sẵn sàng cho các bước 
    nhúng từ, tìm kiếm và truy vấn.
\end{itemize}

\noindent
Quy trình này đảm bảo dữ liệu thô được làm 
sạch, chuẩn hóa và chuyển về cấu trúc nhất quán, 
giảm thiểu nhiễu, đồng thời giữ lại đầy đủ thông 
tin quan trọng cho hệ thống RAG.

\section{Triển khai}

Phần này mô tả chi tiết toàn bộ quá trình triển khai hệ thống FoodChatbot, trong đó
quy trình thu thập dữ liệu (crawling) và tiền xử lý (preprocessing) được đưa lên đầu tiên,
vì đây là nền tảng tạo nên kho tri thức cho hệ thống RAG.

%-----------------------------------------------------------------------
\subsection{Thu thập dữ liệu}

Quá trình thu thập dữ liệu công thức nấu ăn cho 
hệ thống \textbf{FoodChatbot} bao gồm hai giai 
đoạn chính: 
thu thập các link danh mục và thu thập dữ liệu 
chi tiết từ từng công thức.

\subsubsection{Thu thập danh mục}
\begin{itemize}
    \item \textbf{Công nghệ:} Selenium kết hợp 
    trình duyệt tự động (Chrome/undetected driver) 
    để tương tác với trang web động.
    \item Thu thập toàn bộ link danh mục món ăn 
    từ trang chủ.
    \item Lọc các link trong danh sách cấm 
    (blacklist) trước khi lưu lại.
    \item Lưu kết quả vào các file tạm trong 
    thư mục dữ liệu.
\end{itemize}

\subsubsection{Thu thập link công thức chi tiết}
\begin{itemize}
    \item Thu thập từng trang category song song 
    bằng cơ chế \textbf{đa tiến trình 
    (multiprocessing)}.
    \item Hỗ trợ tiếp tục thu thập từ trang 
    hoặc URL đã dừng trước đó 
    (\textbf{resume support}).
    \item Trích xuất tất cả link công thức 
    từ từng trang danh mục.
    \item Dừng thu thập khi không còn link 
    mới hoặc lỗi liên tiếp vượt quá giới hạn.
    \item Lưu link theo từng trang nếu cấu 
    hình bật để tránh mất dữ liệu.
\end{itemize}

\subsubsection{Thu thập chi tiết từng công thức}
\begin{itemize}
    \item Mỗi URL công thức được thu thập và 
    trích xuất các thông tin: mô tả, metadata, 
    nguyên liệu, các bước chế biến, thông tin 
    dinh dưỡng và bình luận.
    \item Sử dụng \textbf{đa luồng 
    (multithreading)} để xử lý nhiều URL cùng lúc.
    \item Quản lý tiến trình bằng hàng đợi và 
    cơ chế khóa để tránh xung đột dữ liệu.
    \item Lưu từng công thức dưới dạng file 
    JSON theo cấu trúc chuẩn trong thư mục dữ liệu.
    \item Các biện pháp an toàn:
    \begin{itemize}
        \item Bỏ qua các trang đã thu thập.
        \item Thử lại khi trình duyệt gặp lỗi.
        \item Thời gian chờ ngẫu nhiên giữa 
        các request để tránh bị chặn.
    \end{itemize}
\end{itemize}

\subsubsection{Tối ưu hóa hiệu năng}
\begin{itemize}
    \item Kết hợp đa tiến trình và đa luồng 
    để tăng tốc độ xử lý.
    \item Hỗ trợ tạm dừng từ URL hoặc trang cụ 
    thể để không bị mất tiến trình.
    \item Ghi nhật ký chi tiết để giám sát 
    tiến trình và thống kê số link/công thức 
    thu được.
    \item Lưu dữ liệu theo từng trang/danh mục 
    và sử dụng ghi file an toàn để giảm rủi ro 
    mất dữ liệu.
\end{itemize}


%-----------------------------------------------------------------------
\subsection{Chuẩn hóa và tiền xử lý dữ liệu}

Dữ liệu thô sau khi thu thập từ các website 
chứa nhiều lỗi định dạng, ký tự đặc biệt, biểu 
tượng unicode, phân tách không đồng nhất và 
các trường dữ liệu khác nhau. Quá trình tiền 
xử lý sử dụng các kỹ thuật Python để làm sạch, 
chuẩn hóa và cấu trúc dữ liệu trước khi lưu trữ 
hoặc đưa vào pipeline RAG.

\subsubsection{Làm sạch dữ liệu văn bản}
\begin{itemize}
    \item Chuẩn hóa Unicode 
    để thống nhất ký tự.
    \item Thay thế các ký tự đặc biệt và ký 
    hiệu như $\degree$, ™, ®, © thành dạng chuẩn.
    \item Chuyển các phân số đặc biệt (ví dụ: 
    $\frac{1}{2}$, $\frac{1}{3}$) sang dạng 
    \texttt{1/2}, \texttt{1/3}.
    \item Loại bỏ ký tự không hiển thị, emoji, 
    whitespace thừa.
    \item Chuẩn hóa khoảng trắng và xuống dòng, 
    đảm bảo text liền mạch.
\end{itemize}

\subsubsection{Chuẩn hóa các trường dữ liệu chính}
\begin{itemize}
    \item \textbf{URL và mô tả:} loại bỏ khoảng 
    trắng thừa, chuẩn hóa text.
    \item \textbf{Nguyên liệu và hướng dẫn:} 
        \begin{itemize}
            \item Chuẩn hóa tên nguyên liệu và 
            đơn vị đo lường (g, ml, tbsp, tsp).
            \item Loại bỏ quảng cáo, watermark 
            hoặc nội dung không liên quan.
            \item Gom các bước nấu bị tách rời 
            hoặc quá ngắn thành các bước hoàn chỉnh.
        \end{itemize}
    \item \textbf{Metadata:} chuyển các thông 
    tin như thời gian nấu, số lượng phần ăn 
    thành dạng số nguyên hoặc phút; chuẩn hóa 
    tên key.
    \item \textbf{Thông tin dinh dưỡng:} chuẩn 
    hóa giá trị và đơn vị cho mỗi chất dinh 
    dưỡng, lưu thành dict \{value, unit\}.
    \item \textbf{Bình luận:} tách author và 
    nội dung bình luận, loại bỏ các chuỗi trống, 
    chuẩn hóa text.
\end{itemize}

\subsubsection{Định dạng dữ liệu theo schema chuẩn}
Dữ liệu sau khi tiền xử lý được lưu trữ theo 
cấu trúc JSON thống nhất, ví dụ:

\begin{verbatim}
{
    "URL": "...",
    "Summary": "...",
    "Ingredients": ["..."],
    "Instructions": ["..."],
    "Metadata": {
        "prep_time_minutes": 10,
        "total_time_minutes": 10,
        "servings": 2,
    },
    "Nutrition": {
        "calories": {"value": 250, "unit": "kcal"},
        "protein": {"value": 15, "unit": "g"},
        ...
    },
    "Comments": [
        {"author": "User1", "text": "..."},
        {"author": null, "text": "..."}
    ]
}
\end{verbatim}

%=======================================================================
\subsection{Vector Database: ChromaDB}

ChromaDB được sử dụng để lưu trữ:

\begin{itemize}
    \item Embedding của các đoạn tài liệu.
    \item Doc-text (nội dung).
    \item Metadata như: nguồn, thời gian nấu, 
    dinh dưỡng.
\end{itemize}

\subsubsection{Cấu trúc lưu trữ trong ChromaDB}
\begin{verbatim}
{
    "id": "recipe_001_chunk_01",
    "embedding": [...],
    "document": "Summary: ... | Ingredients: ... | Instructions: ... | Prep: ...min, Cook: ...min",
    "metadata": {
        "url": "...",
        "prep_time": 0,
        "cook_time": 0,
        "servings": 0,
        "nutr_val_{nutrient}": 0,
        "nutr_unit_{nutrient}": "...",
    }
}
\end{verbatim}

%=======================================================================
\subsection{Retrieval-Augmented Generation (RAG)}

\subsubsection{Thành phần chính}

\begin{itemize}
    \item \textbf{Embedding Generator:} tạo 
    vector cho truy vấn và tài liệu (sử dụng
    mặc định của ChromaDB).
    \item \textbf{Retriever (ChromaDB):} tìm 
    kiếm cosine similarity.
    \item \textbf{Context Injection:} đưa các 
    đoạn liên quan vào prompt.
    \item \textbf{LLM (Gemini):} ghi nhận, phân tích
    yêu cầu người dùng và sinh phản hồi có ngữ cảnh
    (Đầu - Cuối).
\end{itemize}

\subsubsection{Quy trình RAG chi tiết}

\begin{enumerate}
    \item Nhận truy vấn đầu vào (đa ngôn ngữ).
    \item Chuẩn hoá truy vấn bằng Gemini (dịch 
    sang tiếng Anh nếu cần).
    \item Lọc ra những từ khoá quan trọng thể hiện
    sở thích, nguyên liệu, yêu cầu dinh dưỡng.
    \item Sinh embedding truy vấn.
    \item Thực hiện tìm kiếm ngữ nghĩa trong ChromaDB.
    \item Chọn top-$k$ đoạn liên quan nhất sắp xếp
    theo độ tương đồng từ cao đến thấp.
    \item Ghép prompt 
    (ngữ cảnh truy vấn + ngữ cảnh sở thích + truy vấn người dùng).
    \item LLM sinh phản hồi theo ngôn ngữ 
    người dùng.
    \item Gửi kết quả + nguồn trích dẫn về frontend.
\end{enumerate}

%=======================================================================
\subsection{Triển khai Backend với Flask}

Hệ thống backend của FoodChatbot được xây dựng 
bằng Flask, đóng vai trò cầu nối giữa giao diện 
web và pipeline xử lý RAG. Thành phần này chịu 
trách nhiệm phục vụ giao diện người dùng, tiếp 
nhận yêu cầu chat, quản lý phiên hội thoại và 
chuyển tiếp truy vấn đến mô hình chatbot.

\subsubsection{Thành phần chính}

\begin{itemize}
    \item \textbf{Web Server}: cung cấp giao diện 
    chat và các tệp tĩnh như HTML, CSS, JavaScript.
    \item \textbf{REST API}: xử lý các yêu cầu 
    từ frontend bao gồm gửi tin nhắn, reset hội 
    thoại và tải asset.
    \item \textbf{Session Manager}: duy trì ngữ 
    cảnh hội thoại riêng cho từng người dùng 
    thông qua session của Flask.
\end{itemize}

\subsubsection{Các API quan trọng}

\begin{itemize}
    \item \textbf{GET /} \\
          Trả về trang giao diện chính của 
          chatbot (\texttt{index.html}), là điểm 
          vào của ứng dụng web.

    \item \textbf{GET /home/<filename>} \\
          Trả về các tệp CSS, JavaScript và các 
          tài nguyên tĩnh cần thiết cho frontend.

    \item \textbf{POST /api/chat} \\
          Nhận tin nhắn từ người dùng, kích hoạt 
          pipeline xử lý của chatbot và trả về 
          phản hồi dạng JSON.

    \item \textbf{POST /api/reset} \\
          Xóa toàn bộ lịch sử hội thoại trong 
          session, giúp người dùng bắt đầu cuộc 
          trò chuyện mới.
\end{itemize}

\subsubsection{Luồng xử lý của \texttt{/api/chat}}

Khi người dùng gửi yêu cầu POST chứa tin nhắn, 
backend thực hiện quy trình sau:

\begin{enumerate}
    \item Backend nhận payload JSON và lấy nội 
    dung truy vấn.
    \item Truy vấn được chuyển đến chatbot để 
    xử lý.
    \item Bên trong chatbot, pipeline xử lý RAG 
    được thực thi.
    \item Backend tách phần phản hồi và danh 
    sách nguồn tham chiếu (nếu có).
    \item Trả về kết quả dưới dạng JSON: 
    \[
        \{\text{response},\ \text{sources}\}.
    \]
\end{enumerate}

\subsubsection{Luồng xử lý của \texttt{/api/reset}}

\begin{enumerate}
    \item Backend nhận yêu cầu POST từ frontend.
    \item Gọi chức năng reset trong chatbot 
    để xóa toàn bộ lịch sử hội thoại.
    \item Trả về JSON thông báo việc đặt lại 
    hội thoại thành công.
\end{enumerate}

\subsection{Triển khai Frontend}
Giao diện người dùng của FoodChatbot được xây dựng 
bằng HTML, CSS và JavaScript, cung cấp trải nghiệm 
trò chuyện trực quan và thân thiện. Người dùng có thể
gửi câu hỏi, nhận phản hồi và xem nguồn tham chiếu
một cách dễ dàng.

Giao diện chính gồm:
\begin{itemize}
    \item \textbf{Thanh tiêu đề}: hiển thị tên 
    chatbot và logo.
    \item \textbf{Khu vực hiển thị hội thoại}: 
    nơi các tin nhắn từ người dùng và chatbot 
    được trình bày theo dạng bong bóng chat.
    \item \textbf{Thanh nhập tin nhắn}: cho phép 
    người dùng nhập câu hỏi và gửi đi.
    \item \textbf{Nút reset}: để xóa lịch sử 
    hội thoại và bắt đầu cuộc trò chuyện mới.
\end{itemize}

\begin{figure}[!h]
    \centering
    \includegraphics[width=1\textwidth]{fe_chatbot.jpg}
    \caption{Giao diện người dùng của FoodChatbot.}
\end{figure}

\chapter{Kết quả và Phân tích}

Trong chương này, báo cáo trình bày kết quả đạt 
được từ quá trình xây dựng và đánh giá hệ thống 
chatbot gợi ý món ăn. Hệ thống được thiết kế 
nhằm khai thác dữ liệu món ăn thu thập từ 
nguồn \texttt{therecipecritic.com}, kết hợp với 
kiến trúc xử lý ngôn ngữ tự nhiên đa ngôn ngữ 
để tạo ra một chatbot có khả năng tương tác 
tự nhiên, đưa ra gợi ý phù hợp với yêu cầu dinh 
dưỡng và sở thích của người dùng.

\section{Kết quả đạt được}

\subsection{Khả năng hiểu và xử lý đa ngôn ngữ}

Hệ thống chatbot đã hỗ trợ thành công tương tác 
bằng nhiều ngôn ngữ, bao gồm tiếng Việt, tiếng 
Anh và một số ngôn ngữ phổ biến khác. Điều này 
có được nhờ việc sử dụng mô hình ngôn ngữ đa 
ngôn ngữ trong pipeline xử lý ngôn ngữ tự nhiên. 
Chatbot có thể:

\begin{itemize}
    \item Hiểu yêu cầu của người dùng trong nhiều 
    ngôn ngữ khác nhau.
    \item Chuyển đổi yêu cầu thành dạng tiêu 
    chuẩn hoá để tìm kiếm trong cơ sở dữ liệu.
    \item Trả lời bằng đúng ngôn ngữ mà người 
    dùng đang sử dụng.
\end{itemize}

\subsection{Khả năng gợi ý món ăn dựa trên yêu cầu}

Hệ thống có thể phân tích yêu cầu mô tả món ăn 
hoặc bối cảnh do người dùng đưa ra (ví dụ: “tôi 
muốn một món ít béo”, “món phù hợp cho trẻ em”, 
“món ăn nhẹ buổi tối”). Từ đó chatbot thực hiện:

\begin{itemize}
    \item Truy xuất các món ăn trong cơ sở dữ liệu.
    \item So khớp chúng với tiêu chí được suy 
    luận từ ngữ nghĩa yêu cầu người dùng.
    \item Gợi ý một hoặc nhiều món ăn phù hợp 
    nhất.
\end{itemize}

Nhờ đó, chatbot không chỉ đóng vai trò trả lời 
câu hỏi mà còn hoạt động như một trợ lý ẩm thực 
có khả năng phân tích bối cảnh.

\subsection{Phân tích yêu cầu dinh dưỡng và sức khỏe}

Hệ thống cũng được trang bị khả năng phân tích 
yêu cầu về sức khỏe và dinh dưỡng, bao gồm:

\begin{itemize}
    \item Bóc tách các chỉ số dinh dưỡng mà 
    người dùng quan tâm như calories, protein, 
    fat, carbs,...
    \item Hiểu các yêu cầu liên quan đến tình 
    trạng sức khỏe như: bệnh tiểu đường, dị ứng, 
    chế độ ăn kiêng (low-carb, high-protein, 
    gluten-free), hoặc các mục tiêu như tăng 
    cơ/giảm cân.
    \item Kết hợp dữ liệu thực tế trong công 
    thức món ăn để đưa ra danh sách món ăn phù 
    hợp với tình trạng hoặc mục tiêu sức khỏe 
    của người dùng.
\end{itemize}

\subsection{Ưu điểm của hệ thống}

Hệ thống chatbot ẩm thực được xây dựng trên 
nền tảng RAG và tích hợp LLM mang lại nhiều ưu 
điểm nổi bật, thể hiện qua khả năng tương tác, 
chất lượng gợi ý và mức độ cá nhân hoá. Cụ thể:

\begin{itemize}
    \item \textbf{Khả năng tương tác tự nhiên và thân thiện}:  
    Chatbot duy trì phong cách hội thoại linh 
    hoạt, dễ thích nghi với giọng điệu và cách 
    đặt câu hỏi của người dùng, tạo cảm giác 
    trò chuyện liền mạch và dễ tiếp cận.

    \item \textbf{Phân tích tốt các yêu cầu phức tạp}:  
    Nhờ sức mạnh của mô hình ngôn ngữ lớn (LLM), 
    chatbot có thể hiểu và phân tách các yêu 
    cầu nhiều thành phần như:  
    “Gợi ý món không chứa gluten, ít đường, 
    phù hợp cho người tiểu đường và có nguyên 
    liệu dễ mua”.

    \item \textbf{Giảm thiểu hiện tượng ảo giác}:  
    Việc kết hợp RAG giúp mô hình chỉ sử dụng 
    thông tin lấy từ cơ sở dữ liệu món ăn đã 
    được chuẩn hoá, tránh các câu trả lời bịa 
    đặt hoặc không có nguồn.

    \item \textbf{Đảm bảo độ chính xác cao}:  
    Toàn bộ gợi ý được sinh ra từ dữ liệu thu 
    thập thực tế, giúp mô hình trả lời đúng 
    theo công thức, nguyên liệu và hướng dẫn 
    nấu ăn có thật.

    \item \textbf{Lưu trữ và khai thác sở thích người dùng để tăng tính cá nhân hoá}:  
    Hệ thống có thể ghi nhớ một số ngữ cảnh 
    và sở thích từ phiên trò chuyện (ví dụ: 
    món ăn yêu thích, sở thích ăn cay nhẹ, khẩu 
    phần nhỏ, yêu cầu về ăn kiêng).  
    Điều này cho phép chatbot đưa ra các gợi ý 
    phù hợp hơn trong các lượt trò chuyện tiếp 
    theo, nâng cao trải nghiệm cá nhân hoá.

    \item \textbf{Nhận diện yêu cầu chuyên sâu về dinh dưỡng}:  
    Chatbot có thể phân tích các ràng buộc về 
    sức khoẻ hoặc nhu cầu dinh dưỡng như:  
    \begin{itemize}
        \item ít calo, ít carb, giàu protein  
        \item tránh chất béo bão hoà  
        \item phù hợp cho người tiểu đường hoặc 
        người ăn kiêng Keto  
    \end{itemize}
    Qua đó hệ thống có thể lọc và lựa chọn món 
    ăn phù hợp từ cơ sở dữ liệu.

    \item \textbf{Nhận diện và loại bỏ các thành phần cần tránh}:  
    Chatbot có thể hiểu các yêu cầu liên quan 
    đến dị ứng hoặc kiêng khem (như tránh sữa, 
    gluten, hải sản, đậu phộng) và tự động loại 
    bỏ các món chứa thành phần không phù hợp.
\end{itemize}

\subsection{Hạn chế của hệ thống}

Mặc dù đạt hiệu quả tốt, hệ thống vẫn tồn tại 
một số hạn chế như sau:

\begin{itemize}
    \item \textbf{Hạn chế về dữ liệu}:  
    Cơ sở dữ liệu món ăn còn tương đối nhỏ, 
    chủ yếu thu thập từ một nguồn duy nhất. 
    Điều này dẫn đến phạm vi gợi ý hạn chế 
    và chưa có sự phong phú về văn hoá ẩm thực 
    trên thế giới.

    \item \textbf{Thiếu đa dạng về danh mục ẩm thực}:  
    Chưa bao phủ đầy đủ các món ăn đến từ nhiều 
    nền ẩm thực khác nhau. Điều này hạn chế 
    khả năng đáp ứng yêu cầu đa dạng của người dùng.

    \item \textbf{Thiếu dữ liệu dinh dưỡng hoàn chỉnh}:  
    Một số công thức món ăn không có đủ thông 
    tin chi tiết về dinh dưỡng (ví dụ: lượng 
    vitamin, khoáng chất, thành phần vi chất), 
    khiến chatbot chưa thể đáp ứng tốt các yêu 
    cầu chuyên sâu về sức khỏe.

    \item \textbf{Hạn chế do sử dụng API Gemini miễn phí}:  
    Việc sử dụng phiên bản miễn phí của API 
    Gemini khiến tốc độ phản hồi đôi khi chậm, 
    đặc biệt trong các phiên trò chuyện nhiều lượt. Điều này ảnh hưởng đến trải nghiệm người dùng và giới hạn tần suất truy vấn liên tục.

    \item \textbf{Chất lượng dịch sang tiếng Anh chưa tối ưu}:  
    Do mô hình sử dụng bước chuyển đổi truy 
    vấn sang tiếng Anh trước khi truy xuất dữ 
    liệu, một số yêu cầu phức tạp hoặc ngữ 
    cảnh đặc thù bị dịch không sát nghĩa. Hậu 
    quả là hệ thống truy xuất sai hoặc thiếu 
    tài liệu cần thiết, dẫn đến kết quả phản 
    hồi chưa thật sự chính xác.

    \item \textbf{Phụ thuộc mạnh vào cơ sở dữ liệu}:  
    Vì hệ thống được thiết kế để hạn chế ảo 
    giác, mọi phản hồi đều dựa vào dữ liệu đã 
    có. Nếu dữ liệu bị thiếu, sai hoặc không 
    khớp ngữ cảnh, chatbot sẽ không thể bù 
    trừ bằng khả năng suy luận của mô hình 
    ngôn ngữ lớn, dẫn đến các trường hợp hệ 
    thống trả lời “thiếu thông tin”.
\end{itemize}

\subsection{Phương pháp đánh giá}

Mục tiêu của phần đánh giá là đánh giá cả về 
trải nghiệm hội thoại và độ chính 
xác nội dung của hệ thống chatbot trong hai 
kịch bản chính: (1) hội thoại nhiều lượt 
(multi-turn) và (2) trả lời một lượt (one-shot). 
Đánh giá được thiết kế sao cho kết quả vừa phản 
ánh cảm nhận người dùng vừa kiểm tra được mức 
độ dựa vào dữ liệu của mô hình.

\subsubsection{Tổng quan thí nghiệm}
\begin{itemize}
    \item \textbf{Số phiên (sessions)}: 
    30 phiên với multi-turn và 100 phiên với one-shot.
    \item \textbf{Kịch bản multi-turn}: mỗi 
    phiên gồm tối đa 15 lượt prompt từ người 
    đánh giá đến chatbot; đánh giá được ghi 
    lại ở mốc 5, 10 và 15 lượt.
    \item \textbf{Kịch bản one-shot}: mỗi truy 
    vấn độc lập (không có ngữ cảnh trước đó) 
    được đưa vào chatbot một lần; lặp lại 100 
    truy vấn để đánh giá tính ổn định và chính 
    xác từ lượt đầu.
    \item \textbf{Người đánh giá (raters)}: 
    các đánh giá viên là người thật (nhóm kiểm 
    thử nội bộ), thực hiện hội thoại và chấm 
    điểm theo cảm nhận cá nhân.
\end{itemize}

\subsubsection{Quy trình đánh giá chi tiết}
\begin{enumerate}
    \item \textbf{Chuẩn bị prompt}: Người đánh
    giá dựa trên dữ liệu thực tế đã thu thập để
    thực hiện các kịch bản hội thoại và truy vấn.
    \item \textbf{Hướng dẫn người đánh giá}: 
    cung cấp ví dụ minh hoạ, nhấn mạnh:
    \begin{itemize}
        \item Khi chấm \textit{độ thiện cảm}, 
        đánh giá viên cân nhắc tính thân thiện, 
        rõ ràng, dễ đọc và phong cách hội thoại.
        \item Khi chấm \textit{độ chính xác}, 
        chỉ xét những thông tin có thể kiểm chứng 
        trực tiếp từ cơ sở dữ liệu. Nếu chatbot đưa 
        thông tin không có trong DB hoặc trả lời
        không đúng trọng tâm thì tính 
        là không chính xác.
    \end{itemize}
    \item \textbf{Tiến hành phiên multi-turn}:
    \begin{itemize}
        \item Mỗi phiên, đánh giá viên thực hiện 
        tối đa 15 lượt prompt theo kịch bản hoặc 
        tuỳ biến.
        \item Sau lượt 5, 10, 15, đánh giá viên 
        chấm \textit{độ thiện cảm} (thang 1--10) 
        và \textit{độ chính xác tích lũy}.
    \end{itemize}
    \item \textbf{Tiến hành kịch bản one-shot}:
    \begin{itemize}
        \item Với 100 truy vấn one-shot, hệ thống 
        trả lời một lần cho mỗi truy vấn; đánh 
        giá viên gán nhãn chính xác / không 
        chính xác cho từng phản hồi dựa trên 
        dữ liệu trong DB.
    \end{itemize}
\end{enumerate}

\subsubsection{Định nghĩa chỉ số}
\paragraph{Độ thiện cảm (Likability)}
\begin{itemize}
    \item Thang điểm: 1--10 
    (1 = rất khó chịu / vô dụng, 10 = rất thân 
    thiện / cực kỳ hữu ích).
    \item Đánh giá dựa trên: sự tự nhiên 
    của văn phong, lịch sự và thân thiện, 
    rõ ràng trong cách trình bày, 
    tốc độ phản hồi cảm nhận.
    \item Kết quả báo cáo là giá trị trung bình 
    $\bar{L}_n$ trên $S$ phiên ở mốc $n$ lượt, 
    với $n \in \{5,10,15\}$.
\end{itemize}

\paragraph{Độ chính xác tích lũy (Cumulative accuracy)}
\begin{itemize}
    \item Với mỗi phiên $j$ và tại mốc $n$ lượt, 
    định nghĩa:
    \[
    \text{acc}_{j,n} = \frac{\text{\# câu trả lời đúng trong các lượt }1..n}{n}.
    \]
    \item Tổng hợp qua $S$ phiên, độ chính xác 
    tích lũy tại mốc $n$ là:
    \[
    \text{Acc}_n = \frac{1}{S}\sum_{j=1}^{S} \text{acc}_{j,n}.
    \]
    \item "Câu trả lời đúng" được hiểu là: nội 
    dung trả lời khớp (hoặc bao gồm) thông tin 
    xác thực có trong cơ sở dữ liệu; đối với câu hỏi yêu 
    cầu gợi ý danh sách, mỗi item gợi ý được 
    kiểm tra riêng. "Câu trả lời sai" được hiểu là
    nội dung không có trong DB, sai trọng tâm
    yêu cầu, hoặc bịa đặt thông tin.
\end{itemize}

\paragraph{Độ chính xác one-shot}
\begin{itemize}
    \item Với $M=100$ truy vấn độc lập, mỗi truy vấn $i$ có nhãn $c_i\in\{0,1\}$ (0 = sai, 1 = đúng).  
    \[
    \text{OneShotAcc} = \frac{1}{M}\sum_{i=1}^{M} c_i.
    \]
    \item Kết quả báo cáo bằng phần tỷ lệ phần trăm.
\end{itemize}

\subsubsection{Thuật toán đánh giá thống kê}
\begin{itemize}
    \item \textbf{Mean \& Std}: với mỗi chỉ số (likability, Acc\_n, OneShotAcc) tính mean ($\bar{x}$) và độ lệch chuẩn ($\sigma$):
    \[
    \bar{x}=\frac{1}{N}\sum_{i} x_i,\qquad
    \sigma = \sqrt{\frac{1}{N-1}\sum_{i}(x_i-\bar{x})^2}
    \]
\end{itemize}

\subsection{Kết quả định lượng (tổng hợp)}

\noindent Dựa trên 100 phiên multi-turn và 100 truy vấn one-shot, thu được:

\begin{itemize}
    \item \textbf{Độ thiện cảm (mean)}:  
    \[
    \bar{L}_5 = 7.3,\quad \bar{L}_{10}=7.8,\quad \bar{L}_{15}=8.2.
    \]
    \item \textbf{Độ chính xác tích lũy}:  
    \[
    \text{Acc}_5 = 8.2,\quad \text{Acc}_{10}=9.3,\quad \text{Acc}_{15}=9.7.
    \]
    \item \textbf{Độ chính xác one-shot}:  
    \[
    \text{OneShotAcc} = 0.76 \quad(76\% \text{ hoặc } 7.6/10).
    \]
\end{itemize}

\subsection{Phân tích chi tiết kết quả}

\paragraph{1. Tăng hiệu năng theo lượt hội thoại}  
Kết quả cho thấy sự cải thiện rõ rệt về cả độ thiện cảm và độ chính xác khi chuyển từ 5 → 10 → 15 lượt. Giải thích khả dĩ:

\begin{itemize}
    \item \textbf{Viết lại và khắc phục tham chiếu}: sau vài lượt, hệ thống (qua module rewrite) có ngữ cảnh đủ để làm rõ tham chiếu mơ hồ (ví dụ: "món đó", "cái kia"), giúp truy vấn chính xác hơn.
    \item \textbf{Prompt có điều kiện}: chatbot có thể "tối ưu" prompt theo phong cách hội thoại hiện tại (ví dụ người dùng thích ngắn gọn hay chi tiết) — làm tăng cảm nhận thiện cảm.
    \item \textbf{Tăng tiến}: nhiều lượt giúp hệ thống thu thập thêm thông tin liên quan (user preferences, dietary constraints) làm chất lượng retrieval tốt hơn.
\end{itemize}

\paragraph{2. One-shot thấp hơn multi-turn}  
One-shot accuracy (76\%) thấp hơn Acc\_15 (97\%) vì:

\begin{itemize}
    \item Không có ngữ cảnh hội thoại để giải quyết mơ hồ.
    \item Một số truy vấn cần rewrite (ví dụ: "cái kia" không thể xác định).
    \item Dịch ngôn ngữ (nếu có) có thể làm mất một số sắc thái dẫn đến truy vấn không khớp hoàn toàn với DB.
\end{itemize}

\paragraph{3. Phân loại lỗi (error analysis)}  
Tổng hợp các lỗi phổ biến từ 100 phiên được chia thành các nhóm chính sau:

\begin{enumerate}
    \item \textbf{Missing data / Omission}: DB không có thông tin cần thiết (ví dụ: thiếu nutrition field) → chatbot báo "Không có" hoặc trả lời không đầy đủ.
    \item \textbf{Translation mismatch}: bản dịch truy vấn sang tiếng Anh không sát nghĩa → semantic search trả về kết quả không liên quan.
    \item \textbf{Filter misinterpretation}: LLM sinh filter (generate\_chromadb\_filter) sai cú pháp hoặc sai ý (ví dụ: nhầm giữa \texttt{calories} và \texttt{calories per serving}).
    \item \textbf{Partial answer}: chatbot trả lời một phần (ví dụ: chỉ liệt kê vài bước khi người dùng yêu cầu toàn bộ công thức).
    \item \textbf{Hallucination (ít gặp)}: trong một vài trường hợp hiếm, model thêm kiến thức ngoài DB — tuy được hạn chế bằng prompt nhưng vẫn có thể xảy ra khi context không rõ ràng.
\end{enumerate}

\section{Đánh giá kết quả}

Kết quả cho thấy hệ thống chatbot đã đạt được:

\begin{itemize}
    \item Khả năng hiểu yêu cầu người dùng trong nhiều ngôn ngữ.
    \item Gợi ý món ăn chính xác và phù hợp với nhu cầu sức khỏe.
    \item Giảm thiểu ảo giác nhờ phụ thuộc vào cơ sở dữ liệu đã xác thực.
    \item Tương tác thân thiện và chất lượng hội thoại cải thiện theo thời gian.
\end{itemize}

Mặc dù còn hạn chế về độ phong phú của dữ liệu, hệ thống đã chứng minh hiệu quả rõ rệt và hoàn toàn có thể mở rộng khi bổ sung thêm dữ liệu món ăn đa dạng hơn trong tương lai.

% Chương 4: Kết luận
\chapter{Kết luận}

\section{Kết luận \& Hướng phát triển}
[Tóm tắt đóng góp và đề xuất cải tiến hoặc hướng phát triển tiếp theo.]

% % Tài liệu tham khảo
% \chapter*{Tài liệu tham khảo}
\addcontentsline{toc}{chapter}{Tài liệu tham khảo}
% Sử dụng BibTeX hoặc môi trường thebibliography nếu cần
\begin{thebibliography}{9}
\bibitem{transformer} Vaswani Ashish, ``Attention Is All You Need,'' \doi{10.48550/arXiv.1706.03762}
\bibitem{self_attention} The ML Tech Lead!, ``Understanding the Self-Attention Mechanism in 8 min'', \url{www.youtube.com/watch?v=W28LfOld44Y}
\bibitem{multihead_attention} The ML Tech Lead!, ``The Multi-head Attention Mechanism Explained!'', \url{www.youtube.com/watch?v=W6s9i02EiR0&t=34s}
\bibitem{nlp_book} Dan Jurafsky and James H. Martin, ``Speech and Language Processing,'' 3rd Edition, Draft, 2023. \url{https://web.stanford.edu/~jurafsky/slp3/}
\bibitem{gemini_1.5} Google Research, ``Gemini 1.5 Technical Report,'' \doi{10.48550/arXiv.2403.05530}
\bibitem{gemini_2.5} Google Research, ``Gemini 2.5 Technical Report,'' \doi{10.48550/arXiv.2507.06261}
\bibitem{gqa} Google Research, ``GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints,'' \doi{10.48550/arXiv.2305.13245}
\end{thebibliography}

% Phụ lục (Tùy chọn)
\appendix
\chapter{Phụ lục}
% [Thêm kết quả bổ sung, đoạn mã hoặc hướng dẫn sử dụng tại đây.]

\end{document}
