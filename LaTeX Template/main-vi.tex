\documentclass[a4paper,oneside,12pt]{book}

% Packages
\usepackage{graphicx}
\usepackage{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{vietnam}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}

% Define degree symbol command to avoid undefined \degree
\newcommand{\degree}{\ensuremath{^\circ}}

% Geometry setup
\geometry{left=2cm,right=2cm,top=2cm,bottom=2cm}

% Titlepage information
\newcommand{\reporttitle}{Chatbot Ẩm Thực}
\newcommand{\reportauthors}{%
    Cao Hải An - 23001818 \\
    Đặng Thế Anh - 23001821 \\
    Phạm Minh Cương - 23001840 \\
    Đỗ Minh Đức - 23001864 \\
    Phạm Nhật Quang - 23001920
}
\newcommand{\courseinfo}{Mã học phần: MAT1206E \\ Học kỳ 1, Năm học 2025-2026}
\newcommand{\universitylogo}{HUS.png} % Đặt file logo vào cùng thư mục

\newcommand{\doi}[1]{\href{https://doi.org/#1}{\texttt{#1}}} % DOI link command

\begin{document}

% Trang bìa
\begin{titlepage}
    \centering
    \vspace*{-1cm}
    {\LARGE\MakeUppercase{Đại học Quốc gia Hà Nội}\par}
    {\LARGE\MakeUppercase{Trường Đại học Khoa học Tự nhiên}\par}
    \vfill
    \includegraphics[width=0.3\textwidth]{\universitylogo}\par\vfill
    {\Huge \bfseries \reporttitle \par}
    \vspace{1cm}
    {\Large \reportauthors \par}
    \vspace{1cm}
    {\large \courseinfo \par}
    \vfill
\end{titlepage}

% Trang thông tin dự án
\clearpage
\thispagestyle{empty}
\begin{center}
    {\LARGE \textbf{Thông tin Dự án}}\\[1.5em]
    \begin{tabular}{rl}
        \textbf{Học phần:} & MAT1206E -- Nhập môn Trí tuệ Nhân tạo \\
        \textbf{Học kỳ:} & Học kỳ 1, Năm học 2025-2026 \\
        \textbf{Trường:} & VNU-HUS (Đại học Quốc gia Hà Nội -- Trường Đại học Khoa học Tự nhiên) \\
        \textbf{Tên dự án:} & Chatbot Ẩm Thực \\
        \textbf{Ngày nộp:} & 30/11/2025 \\
        \textbf{Báo cáo PDF:} & \href{https://github.com/HaianCao/FoodChatbot/blob/main/LaTeX%20Template/main-vi.pdf}{Báo cáo dự án Chatbot Ẩm Thực} \\
        \textbf{Slide thuyết trình:} & \href{https://github.com/HaianCao/FoodChatbot/blob/main/slide.pptx}{Slide thuyết trình dự án Chatbot Ẩm Thực} \\
        \textbf{Kho GitHub:} & \url{https://github.com/HaianCao/FoodChatbot}
    \end{tabular}
    \\[2em]
    {\Large \textbf{Thành viên nhóm}}\\[1em]
    \begin{tabular}{|l|l|l|l|}
        \hline
        \textbf{Họ tên} & \textbf{Mã sinh viên} & \textbf{Tên GitHub} & \textbf{Đóng góp} \\
        \hline
        Cao Hải An & 23001818 & HaianCao & Xây dựng pipeline chatbot \\
        \hline
        Đặng Thế Anh & 23001821 & DangTAnh & Thu thập dữ liệu \\
        \hline
        Phạm Minh Cương & 23001840 & mcnb2005 & Phát triển giao diện web \\
        \hline
        Đỗ Minh Đức & 23001864 & minhhhduc & Xây dựng module truy xuất dữ liệu \\
        \hline
        Phạm Nhật Quang & 23001920 & NhatquangPham & Tiền xử lý dữ liệu \\
        \hline
    \end{tabular}
\end{center}
\clearpage

\listoffigures % Remove if not needed

\listoftables % Remove if not needed

\tableofcontents
\clearpage

% Chương 1: Giới thiệu
\chapter{Giới thiệu}

\section{Tóm tắt}
Dự án xây dựng một hệ thống chatbot ẩm thực thông 
minh có khả năng cung cấp thông tin toàn diện về 
món ăn, bao gồm cách chế biến, thành phần nguyên 
liệu, giá trị dinh dưỡng và các gợi ý ẩm thực cá 
nhân hóa. Hệ thống được phát triển dựa trên kiến 
trúc Retrieval-Augmented Generation (RAG), kết hợp 
mô hình ngôn ngữ lớn Gemini và cơ sở dữ liệu 
vector để nâng cao khả năng truy xuất và tổng hợp 
tri thức. Dữ liệu ẩm thực được chuẩn hóa, mã hóa 
thành vector nhúng và lưu trữ trong cơ sở dữ liệu vector để đảm bảo việc tìm kiếm thông tin nhanh 
chóng và chính xác. Khi người dùng đặt câu hỏi, 
hệ thống tự động truy xuất các tài liệu liên quan 
và sử dụng Gemini LLM để tạo ra câu trả lời tự 
nhiên, mạch lạc và đáng tin cậy. Kết quả cho 
thấy chatbot có khả năng hiểu ngữ cảnh tốt, hỗ 
trợ người dùng lựa chọn món ăn, gợi ý công thức 
dựa trên nguyên liệu sẵn có và cung cấp thông tin 
dinh dưỡng theo cách thân thiện và dễ sử dụng. Dự 
án là minh chứng cho việc kết hợp RAG và LLM trong 
việc xây dựng các hệ thống tư vấn thông minh trong 
lĩnh vực ẩm thực.

\section{Bài toán đặt ra}
Trong bối cảnh công nghệ số phát triển mạnh mẽ, 
thói quen tiếp cận thông tin của con người đã 
thay đổi đáng kể. Người dùng ngày càng có xu hướng 
tìm kiếm giải pháp nhanh, chính xác và mang tính 
cá nhân hóa cho các nhu cầu hằng ngày, trong đó 
việc lựa chọn món ăn và tìm kiếm công thức nấu 
nướng là những nhu cầu phổ biến nhất. Mặc dù nguồn 
thông tin ẩm thực trên Internet vô cùng phong phú, 
người dùng vẫn gặp nhiều khó khăn do dữ liệu bị 
phân tán, chất lượng không đồng đều và không phải 
lúc nào cũng phù hợp với điều kiện thực tế. Điều 
này đặt ra nhu cầu cần có một hệ thống trợ lý ảo 
có khả năng cung cấp thông tin ẩm thực đáng tin 
cậy, rõ ràng và được cá nhân hóa.

\subsection{Khả năng hiểu ngôn ngữ tự nhiên trong bối cảnh ẩm thực}

Người dùng có thể đưa ra những câu hỏi rất đa 
dạng, từ đơn giản như “Làm mì Ý thế nào?” đến phức 
tạp như “Tôi có gà, nấm và phô mai – có thể nấu 
món gì dưới 30 phút và ít calo?”. Do đó, hệ thống 
cần có khả năng phân tích ý định, nhận diện thực 
thể như nguyên liệu, món ăn, phương pháp chế biến, 
đồng thời hiểu rõ ngữ cảnh của câu hỏi. Bài toán 
đặt ra là tận dụng sức mạnh của mô hình ngôn ngữ 
lớn (LLM) để xử lý ngôn ngữ tự nhiên một cách 
linh hoạt và chính xác trong lĩnh vực ẩm thực.

\subsection{Khả năng truy xuất tri thức chính xác và nhanh chóng}

Kho tri thức ẩm thực rất rộng và bao gồm nhiều 
loại thông tin như nguyên liệu, dinh dưỡng, cách 
chế biến, các biến thể của món ăn và kỹ thuật 
nấu nướng. Hệ thống cần tổ chức và chuẩn hóa dữ 
liệu theo dạng có thể tìm kiếm hiệu quả. Việc sử 
dụng cơ sở dữ liệu vector (vector database) cho 
phép truy vấn dựa trên độ tương đồng ngữ nghĩa 
thay vì tìm kiếm từ khóa truyền thống.

Thách thức kỹ thuật bao gồm:
\begin{itemize}
    \item Chuẩn hóa và làm sạch dữ liệu không đồng 
    nhất.
    \item Mã hóa tri thức bằng các vector 
    nhúng có chất lượng cao.
    \item Thiết kế cơ chế truy vấn tối ưu nhằm 
    đảm bảo kết quả trả về chính xác và phù hợp 
    nhất với truy vấn.
\end{itemize}

\subsection{Sinh câu trả lời tự nhiên, mạch lạc và đáng tin cậy}

Không chỉ đơn thuần truy xuất thông tin, chatbot 
phải tạo ra câu trả lời mạch lạc và hữu ích. Điều 
này bao gồm hướng dẫn nấu ăn theo từng bước rõ 
ràng, giải thích lý do sử dụng nguyên liệu hoặc 
kỹ thuật cụ thể, phân tích khẩu vị, mức độ khó, 
thời gian chế biến, dinh dưỡng, cũng như đề xuất 
điều chỉnh món ăn theo nhu cầu sức khỏe của người 
dùng.

Việc kết hợp kiến trúc Retrieval-Augmented 
Generation (RAG) và mô hình Gemini LLM đảm bảo 
rằng câu trả lời vừa dựa trên tri thức chính 
xác vừa có tính tự nhiên và dễ hiểu.

\subsection{Cá nhân hóa theo nhu cầu và ràng buộc thực tế của người dùng}

Một hệ thống chatbot thông minh cần cung cấp gợi 
ý phù hợp với từng cá nhân, bao gồm:
\begin{itemize}
    \item Sở thích cá nhân như mức độ cay, khẩu 
    vị hoặc phong cách ẩm thực.
    \item Các chế độ dinh dưỡng đặc thù (ăn chay, 
    keto, low-carb, không gluten).
    \item Dị ứng hoặc hạn chế trong ăn uống.
    \item Nguyên liệu hiện có trong bếp.
    \item Mục tiêu sức khỏe (giảm cân, tăng cơ 
    hoặc giảm đường).
\end{itemize}

Do đó, bài toán đặt ra là tích hợp dữ liệu hồ sơ 
người dùng vào pipeline của hệ thống để tối ưu hóa 
khả năng cá nhân hóa trong từng câu trả lời.

\subsection{Ý nghĩa thực tiễn và tác động}

Khi giải quyết tốt các yêu cầu trên, hệ thống 
chatbot ẩm thực mang đến nhiều giá trị thực tiễn:
\begin{itemize}
    \item Giảm thời gian tìm kiếm và tổng hợp 
    thông tin từ nhiều nguồn.
    \item Hỗ trợ người dùng trong quá trình nấu 
    ăn với các hướng dẫn trực quan.
    \item Khuyến khích khám phá các món ăn mới 
    phù hợp với khẩu vị cá nhân.
    \item Cung cấp thông tin dinh dưỡng một cách 
    rõ ràng và chính xác.
    \item Mang lại trải nghiệm nấu nướng tiện lợi 
    và hiệu quả hơn nhờ sự hỗ trợ của AI.
\end{itemize}

Dự án cũng minh chứng cho khả năng ứng dụng của 
các mô hình LLM kết hợp RAG trong việc phát triển 
hệ thống tư vấn thông minh trong lĩnh vực ẩm 
thực, giải quyết hiệu quả bài toán truy xuất 
tri thức không cấu trúc quy mô lớn.

% Chương 2: Phương pháp & Triển khai
\chapter{Phương pháp}

Dự án chatbot ẩm thực được xây dựng dựa trên sự 
kết hợp giữa mô hình ngôn ngữ lớn (Large Language 
Model -- LLM), kiến trúc Retrieval-Augmented 
Generation (RAG) và cơ sở dữ liệu vector nhằm 
tối ưu hóa khả năng truy xuất tri thức ẩm thực 
cũng như sinh phản hồi tự nhiên, chính xác và 
đáng tin cậy. Phần này trình bày chi tiết cách 
tiếp cận tổng thể, cơ sở lý thuyết, kiến trúc 
thành phần, thuật toán chính và dữ liệu sử dụng 
trong hệ thống.

\section{Phương hướng tiếp cận}

Cách tiếp cận tổng thể của dự án dựa trên nguyên 
tắc: kết hợp sức mạnh sinh ngôn ngữ của LLM 
với khả năng tìm kiếm tri thức theo ngữ nghĩa 
của cơ sở dữ liệu vector. Điều này giúp hệ 
thống khắc phục hạn chế về tính cập nhật của 
mô hình ngôn ngữ đơn thuần tức không thể tự động 
biết thông tin mới sau thời điểm chúng được huấn 
luyện, đồng thời duy trì 
chất lượng ngôn ngữ tự nhiên và khả năng gợi ý 
chính xác theo bối cảnh. Hệ thống được triển 
khai theo pipeline RAG tiêu chuẩn với các bước 
chi tiết như sau:

\begin{itemize}
    \item \textbf{Kết hợp LLM và RAG}: Mô hình 
    LLM (Google Gemini) được sử dụng để xử lý 
    truy vấn đầu vào của người dùng với khả năng 
    hỗ trợ đa ngôn ngữ. Hệ thống chuyển đổi truy 
    vấn sang tiếng Anh nhằm tối ưu hóa quá trình 
    tìm kiếm trong cơ sở dữ liệu và đảm bảo tính 
    nhất quán trong biểu diễn văn bản. Sau khi 
    truy xuất được các ngữ cảnh phù hợp, LLM 
    tiếp tục sinh phản hồi bằng tiếng Anh sau đó
    phản hồi này được dịch lại sang chính ngôn ngữ 
    ban đầu của người dùng. Kiến trúc RAG đóng 
    vai trò bổ sung tri thức từ kho dữ liệu được 
    tổ chức dưới dạng vector, giúp hệ thống nâng 
    cao độ chính xác và tính tin cậy của câu trả 
    lời so với việc chỉ sử dụng LLM đơn thuần.

    \item \textbf{Thu thập dữ liệu ẩm thực}: Dữ 
    liệu được lấy từ trang web nấu ăn uy tín 
    thông qua hệ thống khai thác dữ liệu. Bộ dữ liệu bao 
    gồm thông tin chi tiết về tên món ăn, mô tả sơ lược, \
    thành phần nguyên liệu,
    hướng dẫn nấu theo từng bước, thời gian chế 
    biến, khẩu phần, giá trị dinh dưỡng.
    
    \item \textbf{Tiền xử lý và chuẩn hóa dữ liệu}: 
    Dữ liệu thu thập thường chứa nhiều nhiễu, sai 
    sót về chính tả hoặc về cách biểu diễn số học, 
    và không đồng nhất về đơn vị. Do đó, hệ thống 
    áp dụng các bước xử lý chuẩn hóa unicode, thay 
    thế ký tự đặc biệt, chuẩn hóa phân số, thời gian, 
    tách số và đơn vị, tách bình luận và tên,... Các đặc 
    trưng quan trọng được trích xuất để phục vụ 
    cho việc embedding và truy xuất dữ liệu.
    
    \item \textbf{Sinh vector nhúng}: Văn bản 
    sau khi được chuẩn hóa được đưa vào mô hình 
    nhúng từ để chuyển đổi thành vector biểu 
    diễn tương ứng. Các vector này mã hóa thông 
    tin ngữ nghĩa của món ăn giúp hệ thống có thể 
    truy vấn hiệu quả theo nghĩa (semantic search) 
    thay vì chỉ tìm kiếm theo từ khóa.
    
    \item \textbf{Lưu trữ tri thức vào cơ sở 
    dữ liệu vector}: Các vector nhúng cùng 
    với metadata được lưu trữ trong ChromaDB. 
    Cơ sở dữ liệu vector cho phép hệ thống thực 
    hiện tìm kiếm dựa trên độ tương đồng cosine, 
    tối ưu cho các truy vấn phức tạp liên quan 
    đến ngữ cảnh và ý định người dùng.
    
    \item \textbf{Tìm kiếm ngữ nghĩa}: Khi người 
    dùng đưa ra câu hỏi, hệ thống sinh vector nhúng 
    cho truy vấn, sau đó truy xuất các vector 
    gần nhất trong không gian nhúng. Các 
    tài liệu liên quan nhất được lựa chọn và 
    ghép vào ngữ cảnh đầu vào cho mô hình LLM.
    
    \item \textbf{Tổng hợp và sinh phản hồi}: 
    LLM Gemini sử dụng ngữ cảnh từ bước truy 
    xuất để sinh phản hồi mạch lạc, đầy đủ và 
    chính xác. Nhờ cơ chế này, hệ thống vừa đảm 
    bảo tính thực tiễn của tri thức ẩm thực, vừa 
    duy trì khả năng diễn đạt tự nhiên và tùy 
    biến theo nhu cầu người dùng.
\end{itemize}

Với pipeline RAG, dự án chatbot ẩm thực đạt được 
sự cân bằng giữa khả năng sinh ngôn ngữ tự nhiên 
của LLM và độ chính xác trong cung cấp tri thức 
thực tế. Điều này cho phép chatbot không chỉ trả 
lời câu hỏi về công thức nấu ăn, nguyên liệu hay 
dinh dưỡng, mà còn đưa ra gợi ý tùy chỉnh theo 
sở thích cá nhân, hạn chế ăn uống hoặc nguyên 
liệu có sẵn của người dùng.

\section{Cơ sở lý thuyết}

\subsection{Mô hình ngôn ngữ lớn (Large 
Language Model -- LLM)}

Hệ thống sử dụng mô hình Gemini, thuộc họ các 
mô hình ngôn ngữ lớn (LLM) hiện đại, được huấn 
luyện trên tập dữ liệu văn bản đa dạng và quy 
mô lớn. Về mặt kiến trúc, Gemini (tương tự các 
LLM hiện đại khác) được xây dựng dựa trên 
Transformer nhiều tầng.

\paragraph{Kiến trúc Transformer}
Transformer được mô tả rất rõ ràng trong 
\cite{transformer} gồm các lớp xếp chồng (stacked 
layers), mỗi lớp bao gồm hai thành phần 
chính: cơ chế Self-Attention và 
mạng Feed-Forward vị trí-tách rời 
(position-wise feed-forward). Ở cấp độ token, 
đầu vào là một chuỗi token 
\(x_1, x_2, \dots, x_n\) được ánh xạ thành 
embedding \(E = [e_1, \dots, e_n]\).

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\textwidth]{Transformer.png}
    \caption{Kiến trúc mô hình Transformer.\cite{transformer}}
\end{figure}
\paragraph{Self-Attention}
Cho một lớp attention đơn, với ma trận trọng 
số \(W_Q, W_K, W_V\) chuyển embedding thành 
các vectors Query \(Q\), Key \(K\) và Value \(V\):
\[
Q = E W_Q,\quad K = E W_K,\quad V = E W_V.
\]
Điểm attention giữa token i và token j được tính 
bằng:
\[
\text{score}(i,j) = \frac{q_i \cdot k_j}{\sqrt{d_k}},
\]
sau đó áp dụng softmax để có trọng số attention:
\[
\alpha_{ij} = \frac{\exp(\text{score}(i,j))}{\sum_{t=1}^n \exp(\text{score}(i,t))}.
\]
Biểu diễn đầu ra cho token i là tổng có trọng 
số các value:
\[
z_i = \sum_{j=1}^n \alpha_{ij} v_j.
\]
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\textwidth]{self_attention.png}
    \caption{Cơ chế Self-Attention.\cite{self_attention}}
\end{figure}

\textbf{Multi-head attention} tách không gian 
biểu diễn thành nhiều head độc lập, cho phép mô 
hình học nhiều loại quan hệ khác nhau giữa token.
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.8\textwidth]{multihead_attention.png}
    \caption{Cơ chế Multi-Head Attention.\cite{multihead_attention}}
\end{figure}

\paragraph{Feed-Forward Layers}
Sau attention, mỗi token đi qua một mạng 
feed-forward theo từng vị trí:
\[
\text{FFN}(x) = \text{ReLU}(x W_1 + b_1) W_2 + b_2.
\]
Các lớp này tạo ra biểu diễn phi tuyến mạnh hơn 
cho từng token.

\paragraph{Layer Normalization \& Residual Connection}

Trong mỗi tầng con của Transformer (self–attention hoặc feed–forward), đầu vào $x$ được xử lý qua hai cơ chế quan trọng: \textit{residual connection} và \textit{layer normalization}. Hai cơ chế này giúp ổn định gradient, duy trì thông tin gốc và tăng tốc độ hội tụ của mô hình.

\subparagraph{Residual Connection}

Cho đầu vào của sub-layer là $x$ và phép biến đổi của sub-layer là $\mathrm{SubLayer}(x)$.  
Residual connection được định nghĩa:

\[
h = x + \mathrm{SubLayer}(x).
\]

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.6\textwidth]{residual_connection.png}
    \caption{Cơ chế Residual Connection.\cite{nlp_book}}
\end{figure}

Cơ chế này đảm bảo rằng thông tin ban đầu vẫn được giữ lại, đồng thời giúp giảm hiện tượng mất mát gradient (vanishing gradient).

\subparagraph{Layer Normalization}

Sau khi tạo ra $h$, ta chuẩn hoá từng vector theo chiều ẩn.  
Giả sử $h = (h_1, h_2, \dots, h_d)$ với $d$ là kích thước embedding.

Trung bình và phương sai theo từng vector được tính như sau:

\[
\mu = \frac{1}{d} \sum_{i=1}^{d} h_i,
\qquad
\sigma^2 = \frac{1}{d} \sum_{i=1}^{d} (h_i - \mu)^2.
\]

Layer Normalization được áp dụng cho từng phần tử:

\[
\mathrm{LayerNorm}(h)_i
= 
\gamma \cdot 
\frac{h_i - \mu}{\sqrt{\sigma^2 + \epsilon}} 
+ \beta,
\]

trong đó $\gamma$ và $\beta$ là các tham số học được, và $\epsilon$ đảm bảo ổn định số học.

\subparagraph{Công thức tổng quát của Transformer Block}

Residual và Layer Normalization được gộp lại thành:

\[
\mathrm{Output}
=
\mathrm{LayerNorm}\!\left(
x + \mathrm{SubLayer}(x)
\right).
\]

Khai triển đầy đủ theo từng phần tử:

\[
\mathrm{Output}_i
=
\gamma \cdot
\frac{
\left[x_i + \mathrm{SubLayer}(x)_i\right] - \mu
}{
\sqrt{\sigma^2 + \epsilon}
}
+ \beta,
\]

với:

\[
\mu
=
\frac{1}{d}
\sum_{j=1}^{d}
\left(x_j + \mathrm{SubLayer}(x)_j\right),
\quad
\sigma^2
=
\frac{1}{d}
\sum_{j=1}^{d}
\left[
\left(x_j + \mathrm{SubLayer}(x)_j\right) - \mu
\right]^2.
\]

Transformer nhiều tầng cho phép mô hình nắm bắt 
quan hệ ngữ cảnh dài hạn, suy luận phức tạp và 
sinh ngôn ngữ tự nhiên chất lượng cao — những 
yếu tố cần thiết cho việc hiểu truy vấn ẩm thực 
phức tạp và sinh hướng dẫn nấu ăn.

\paragraph{Tính năng đa ngôn ngữ và tiền xử lý truy vấn}
Trong dự án, Gemini được khai thác với khả năng 
đa ngôn ngữ: hệ thống có thể tiền xử lý truy vấn 
đầu vào (chẳng hạn dịch sang tiếng Anh để tương 
thích tốt hơn với vector DB / vector nhúng được 
thống nhất), sau đó sinh phản hồi bằng ngôn ngữ 
người dùng. Việc này tối ưu hóa độ tương đồng 
ngữ nghĩa khi nhúng và truy xuất.

\paragraph{Cải tiến kiến trúc trong Gemini 2.5 Flash-Lite\cite{gemini_2.5}}
Khác với kiến trúc Transformer 
tiêu chuẩn (Dense Transformer) nêu trên, mô hình 
Gemini 2.5 Flash-Lite tích hợp các kỹ thuật tối 
ưu hóa hiện đại nhằm cân bằng giữa hiệu năng tính 
toán và khả năng suy luận, đặc biệt phù 
hợp cho các hệ thống yêu cầu độ trễ thấp:

\textbf{1. Mixture-of-Experts (MoE) thưa\cite{gemini_1.5}:} 
Thay vì kích hoạt toàn bộ tham số mạng cho mỗi 
token, hệ thống sử dụng kiến trúc MoE thưa 
(Sparse MoE). Mỗi lớp Feed-Forward bao gồm tập 
hợp các "chuyên gia" (experts) 
$\{E_1, \dots, E_N\}$. Một mạng Gating 
$G(x)$ sẽ chọn ra top-k chuyên gia phù hợp 
nhất cho đầu vào $x$:
\[
y = \sum_{i \in \text{Top-k}(G(x))} G(x)_i \cdot E_i(x).
\]
Điều này giúp giảm chi phí tính toán tuyến tính 
trong khi vẫn duy trì dung lượng bộ nhớ 
(capacity) của một mô hình lớn.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{MOE.png}
    \caption{Kiến trúc Mixture-of-Experts (MoE).\cite{moe}}
\end{figure}

\textbf{2. Grouped-Query Attention (GQA)\cite{gqa}:} 
Để tối ưu hóa bộ nhớ KV-Cache trong quá trình 
suy luận (inference), mô hình thay thế 
Multi-Head Attention truyền thống bằng 
Grouped-Query Attention. Số lượng đầu Key 
($H_K$) và Value ($H_V$) ít hơn số lượng đầu 
Query ($H_Q$) theo tỷ lệ $G = H_Q / H_K$. 
Điều này giảm băng thông bộ nhớ cần thiết để 
tải các ma trận $K, V$:
\[
\text{GQA}(Q, K, V) = \text{Concat}(\text{head}_1, \dots, \text{head}_{H_Q}) W_O,
\]
trong đó mỗi nhóm $G$ queries chia sẻ chung một cặp đầu $k, v$.

\textbf{3. Rotary Positional Embeddings (RoPE):} 
Thay vì cộng vector vị trí tuyệt đối, Gemini 
sử dụng mã hóa vị trí quay (RoPE) để bảo toàn 
tốt hơn tính chất khoảng cách tương đối giữa 
các token. Với vector $x$ tại vị trí $m$, phép 
biến đổi được thực hiện bằng phép quay trong 
không gian phức:
\[
f(x, m) = (x_1, x_2, \dots, x_d) \otimes (\cos m\theta, \cos m\theta, \dots),
\]
kết hợp với thành phần ảo để xoay vector, cho 
phép mô hình ngoại suy tốt hơn trên các ngữ cảnh 
dài (long-context extrapolation).

\textbf{4. Hàm kích hoạt và Chuẩn hóa:} 
Cải thiện tính ổn định hội tụ bằng cách thay 
thế LayerNorm truyền thống bằng \textbf{RMSNorm} 
(Root Mean Square Normalization) và sử dụng 
hàm kích hoạt \textbf{SwiGLU} thay cho ReLU 
trong các khối FFN:
\[
\text{RMSNorm}(x) = \frac{x}{\sqrt{\frac{1}{d} \sum_{i=1}^d x_i^2 + \epsilon}} \cdot \gamma,
\]
\[
\text{SwiGLU}(x, W, V, W_2) = (\text{Swish}(xW) \otimes (xV)) W_2.
\]

\subsection{Vector Database và Nhúng từ}

\paragraph{Ý tưởng nhúng từ}
Nhúng từ là hàm ánh xạ \(f: \text{Text} \to 
\mathbb{R}^d\) đưa một đoạn văn bản (ví dụ: 
tên món, danh sách nguyên liệu, bước nấu) về 
không gian vector \(d\)-chiều sao cho các văn 
bản có ý nghĩa tương tự nằm gần nhau.

\paragraph{Các trường dữ liệu}
Mỗi mục trong database gồm:
\begin{itemize}
    \item \texttt{ids}: Khóa duy nhất cho mỗi document.
    \item \texttt{embeddings}: Vectơ \(\in 
    \mathbb{R}^d\).
    \item \texttt{documents}: Nội dung văn bản thô 
    (ví dụ: "Ingredients: ...; Steps: ...").
    \item \texttt{metadatas}: Metadata bổ sung 
    (ví dụ: tên món, thời gian nấu, dinh dưỡng,...).
\end{itemize}

\paragraph{Ưu điểm của vector DB}
\begin{itemize}
    \item \textbf{Tìm kiếm ngữ nghĩa}: truy 
    vấn không phụ thuộc vào từ khóa chính xác.
    \item \textbf{Khả năng mở rộng}: lưu trữ 
    hàng chục ngàn đến hàng triệu vectors, kết 
    hợp ANN (Approximate Nearest Neighbor Search 
    - Tìm kiếm láng giềng gần đúng) để truy vấn hiệu quả.
    \item \textbf{Dễ cập nhật tri thức}: chỉ 
    cần thêm/sửa văn bản mà không phải fine-tune 
    LLM.
\end{itemize}

\subsection{Độ tương đồng cosine}

\paragraph{Định nghĩa độ tương đồng cosine\cite{nlp_book}}
Với hai vector \(u, v \in \mathbb{R}^d\), độ 
tương đồng cosine được tính:
\[
\text{cosine}(u,v) = \frac{u \cdot v}{\|u\| \cdot \|v\|} = \frac{\sum_{i=1}^d u_i v_i}{\sqrt{\sum_{i=1}^d u_i^2} \cdot \sqrt{\sum_{i=1}^d v_i^2}} 
\]
Mục tiêu là chọn những văn bản có cosine cao 
nhất so với vector nhúng của truy vấn.

\paragraph{Thuộc tính và ngưỡng}
\begin{itemize}
    \item Giá trị nằm trong \([-1,1]\), nhưng 
    với nhúng từ từ LLM/public models thường 
    nằm trong \([0,1]\) do cấu trúc nhúng.
    \item Thực tiễn: đặt ngưỡng lọc (ví dụ 
    0.65–0.75) để loại bỏ văn bản không liên 
    quan; ngưỡng cụ thể cần hiệu chỉnh dựa trên 
    đánh giá thực nghiệm.
    \item Kết hợp với ranking dựa trên cosine 
    để chọn top-\(k\) văn bản (k thường trong 
    khoảng 3–10).
\end{itemize}

\subsection{Kiến trúc Retrieval-Augmented Generation (RAG)\cite{nlp_book}}

\paragraph{Nguyên lý tổng quát}

RAG là một kiến trúc lai giữa khả năng 
hiểu và sinh ngôn ngữ của LLM và khả 
năng truy xuất tri thức chính xác của 
cơ sở dữ liệu dạng vector. Khi người dùng đưa 
ra một câu hỏi, hệ thống không để mô hình LLM 
tự trả lời dựa trên trí nhớ nội tại, mà thay vào đó:
\begin{enumerate}
    \item Truy xuất tri thức liên quan một cách 
    có kiểm soát từ cơ sở dữ liệu.
    \item Kết hợp tri thức đó vào prompt để 
    LLM sinh ra câu trả lời dựa trên thông 
    tin có thật.
\end{enumerate}

Cách tiếp cận này tối ưu cho các bài toán yêu 
cầu thông tin cập nhật, chính xác, giảm thiểu sai 
sót do mô hình tự bịa (hallucination).

\paragraph{Hệ thống gồm 2 mô-đun chính}
\begin{enumerate}
    \item \textbf{Retriever}: nhận câu hỏi, sinh 
    embedding, so khớp với các vector trong 
    database và trả về các đoạn văn bản liên 
    quan nhất.
    \item \textbf{Generator}: dùng mô hình 
    LLM để sinh câu trả lời dựa trên ngữ cảnh 
    đã được truy xuất.
\end{enumerate}

Hai mô-đun hoạt động độc lập nhưng liên kết chặt 
chẽ, đảm bảo luồng xử lý rõ ràng và dễ mở rộng.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{rag_architecture.png}
    \caption{Kiến trúc Retrieval-Augmented Generation (RAG).\cite{nlp_book}}
\end{figure}

\paragraph{Lợi ích nổi bật của RAG}
\begin{itemize}
    \item \textbf{Giảm hallucination}: LLM phải 
    dựa trên các đoạn ngữ cảnh có thật, giúp hạn 
    chế sinh thông tin sai.
    \item \textbf{Không cần huấn luyện lại LLM}: 
    chỉ việc cập nhật vector DB là hệ thống có 
    thêm tri thức mới.
    \item \textbf{Tùy biến theo mục tiêu}: có 
    thể thay đổi chiến lược truy xuất (top-$k$, 
    filter theo tag nguyên liệu, theo calories, 
    \dots), hoặc tùy chỉnh quy tắc tạo prompt.
\end{itemize}

\paragraph{Chi tiết prompt injection}
Thực tế thường áp dụng chiến lược:
\begin{enumerate}
    \item Lấy top-\(k\) đoạn liên quan.
    \item Nếu các đoạn dài, tóm tắt mỗi đoạn 
    bằng một câu ngắn (tóm tắt) trước khi 
    chèn vào prompt.
    \item Chèn metadata quan trọng (ví dụ: 
    nguồn, thời gian nấu, lượng calo).
    \item Cấu trúc prompt: \texttt{[System 
    Instruction] + [Retrieved Contexts] + 
    [User Query]}.
\end{enumerate}

\subsection{Quy trình tổng quát}

Thuật toán chính của hệ thống được thiết kế xoay 
quanh pipeline Retrieval-Augmented Generation (RAG), 
kết hợp giữa khả năng suy luận ngôn ngữ của mô hình 
sinh ngôn ngữ và khả năng truy xuất tri thức theo ngữ nghĩa 
từ vector database. Pipeline thuật toán gồm các bước sau:

\subsubsection{1. Nhận và chuẩn hoá truy vấn người dùng}

\begin{itemize}
    \item Người dùng gửi câu hỏi bất kỳ liên quan 
    đến chủ đề mà chatbot hỗ trợ.
    \item Truy vấn được đưa vào mô-đun đảm nhiệm việc:
    \begin{itemize}
        \item Phát hiện ngôn ngữ đầu vào.
        \item Chuẩn hóa và loại bỏ nhiễu trong câu hỏi.
        \item Dịch truy vấn sang ngôn ngữ phù hợp nếu cần 
        (để tương thích với dữ liệu embedding 
        trong DB).
    \end{itemize}
\end{itemize}

\subsubsection{2. Sinh embedding cho truy vấn}
\begin{itemize}
    \item Truy vấn được đưa vào mô hình nhúng từ
    để chuyển đổi thành vector biểu diễn:
    \[
        q = \text{Embed}(query)
    \]
    \item Kết quả là vector biểu diễn ngữ nghĩa 
    có độ dài cố định, 
    dùng để truy vấn vào cơ sở dữ liệu vector.
\end{itemize}

\subsubsection{3. Truy vấn ngữ nghĩa}
\begin{itemize}
    \item Cơ sở dữ liệu vector lưu các embedding của tài liệu 
    ẩm thực.
    \item Hệ thống thực hiện tìm kiếm top-$k$ 
    văn bản tương đồng nhất:
    \[
        \text{docs} = \text{VectorDB.top\_k}(q, k)
    \]
    \item Độ tương đồng được tính bằng cosine 
    similarity:
    \[
        \text{cosine}(q, d_i) = \frac{q \cdot d_i}{\|q\|\|d_i\|}
    \]
    \item Các đoạn văn liên quan nhất được trả 
    về kèm metadata ví dụ như tên món, nguyên liệu, thời 
    gian nấu, mô tả, v.v.
\end{itemize}

\subsubsection{4. Tiêm ngữ cảnh (Context Injection)}
\begin{itemize}
    \item Các đoạn thu được được tổng hợp lại 
    thành một khối văn bản dạng:
    \[
        C = \text{concat}(d_1, d_2, \ldots, d_k)
    \]
    \item Context được chèn vào prompt theo 
    cấu trúc:
    \[
        P = [System\ Instructions] + [Retrieved\ Context\ C] + [User\ Query]
    \]
    \item Đây là giai đoạn quan trọng đảm bảo 
    mô hình sinh ngôn ngữ không sinh thông tin sai (hallucination).
\end{itemize}

\subsubsection{5. Sinh phản hồi (Answer Generation)}
\begin{itemize}
    \item Prompt hoàn chỉnh được đưa vào mô hình 
    sinh ngôn ngữ.
    \item Mô hình sinh ngôn ngữ sinh câu trả 
    lời bằng ngôn ngữ phù hợp với hệ thống, sau khi:
    \begin{itemize}
        \item Kết hợp tri thức từ context đã 
        truy xuất.
        \item Tối ưu nội dung theo hướng hội 
        thoại và hữu ích.
    \end{itemize}
    \item Đầu ra sau đó được dịch ngược trở lại
    đúng ngôn ngữ của người dùng nếu cần.
\end{itemize}

\chapter{Triển khai}

\section{Dữ liệu sử dụng}

Dữ liệu cho hệ thống chatbot ẩm thực được thu 
thập trực tiếp từ trang web 
\texttt{https://therecipecritic.com} thông qua 
quá trình khai thác tự động. Mỗi trang công thức 
nấu ăn được tách và lưu trữ dưới dạng một tệp 
JSON chứa đầy đủ các thành phần thông tin cần 
thiết phục vụ cho bước trích xuất tri thức và 
tạo nhúng từ.

\subsection{Cấu trúc dữ liệu thô}

Mỗi công thức sau khi khai thác được biểu diễn 
dưới dạng một đối tượng JSON có cấu trúc thống 
nhất như sau:

\begin{itemize}
    \item \textbf{URL}: đường dẫn tuyệt đối đến 
    trang công thức gốc.
    \item \textbf{Summary}: đoạn mô tả ngắn gọn 
    về món ăn.
    \item \textbf{Metadata}: tập hợp thông tin 
    định lượng như thời gian sơ chế, thời gian 
    nấu, tổng thời gian và số khẩu phần.
    \item \textbf{Ingredients}: danh sách nguyên 
    liệu cần thiết, mỗi mục là một chuỗi mô tả 
    đầy đủ định lượng và tên nguyên liệu.
    \item \textbf{Instructions}: chuỗi các bước 
    hướng dẫn nấu ăn theo thứ tự.
    \item \textbf{Nutrition}: thông tin dinh 
    dưỡng cho mỗi khẩu phần (calories, fat, 
    protein, v.v.).
    \item \textbf{Comments}: các bình luận từ 
    người dùng thật, giúp chatbot có thêm dữ 
    liệu phản ánh trải nghiệm thực tế.
\end{itemize}

%-----------------------------------------------------------------------
\section{Thu thập dữ liệu}

Quá trình thu thập dữ liệu công thức nấu ăn cho 
hệ thống \textbf{FoodChatbot} bao gồm ba giai 
đoạn chính: 
thu thập các link danh mục, thu thập link công
thức chi tiết rồi từ đấy thu thập dữ liệu 
chi tiết của từng công thức.

\textbf{Công cụ chính:} Sử dụng Selenium để 
tương tác với trang web động, kết hợp với 
các kỹ thuật Chrome/undetected driver để 
tránh bị chặn.

\subsection*{Thu thập danh mục}
\begin{itemize}
    \item Thu thập toàn bộ link danh mục món ăn 
    từ trang chủ.
    \item Lọc các link trong danh sách cấm 
    (blacklist) trước khi lưu lại.
    \item Lưu kết quả vào các file tạm trong 
    thư mục dữ liệu.
\end{itemize}

\subsection*{Thu thập link công thức chi tiết}
\begin{itemize}
    \item Thu thập từng trang category song song 
    bằng cơ chế \textbf{đa tiến trình 
    (multiprocessing)}.
    \item Hỗ trợ tiếp tục thu thập từ trang 
    hoặc URL đã dừng trước đó 
    (\textbf{resume support}).
    \item Trích xuất tất cả link công thức 
    từ từng trang danh mục.
    \item Dừng thu thập khi không còn link 
    mới hoặc lỗi liên tiếp vượt quá giới hạn.
    \item Lưu link theo từng trang nếu cấu 
    hình bật để tránh mất dữ liệu.
\end{itemize}

\subsection*{Thu thập chi tiết từng công thức}
\begin{itemize}
    \item Mỗi URL công thức được thu thập và 
    trích xuất các thông tin: mô tả, metadata, 
    nguyên liệu, các bước chế biến, thông tin 
    dinh dưỡng và bình luận.
    \item Sử dụng \textbf{đa luồng 
    (multithreading)} để xử lý nhiều URL cùng lúc.
    \item Quản lý tiến trình bằng hàng đợi và 
    cơ chế khóa để tránh xung đột dữ liệu.
    \item Lưu từng công thức dưới dạng file 
    JSON theo cấu trúc chuẩn trong thư mục dữ liệu.
    \item Các biện pháp an toàn:
    \begin{itemize}
        \item Bỏ qua các trang đã thu thập.
        \item Thử lại khi trình duyệt gặp lỗi.
        \item Thời gian chờ ngẫu nhiên giữa 
        các request để tránh bị chặn.
    \end{itemize}
\end{itemize}

\subsubsection{Tối ưu hóa hiệu năng}
\begin{itemize}
    \item Kết hợp đa tiến trình và đa luồng 
    để tăng tốc độ xử lý.
    \item Hỗ trợ tạm dừng từ URL hoặc trang cụ 
    thể để không bị mất tiến trình.
    \item Ghi nhật ký chi tiết để giám sát 
    tiến trình và thống kê số link/công thức 
    thu được.
    \item Lưu dữ liệu theo từng trang/danh mục 
    và sử dụng ghi file an toàn để giảm rủi ro 
    mất dữ liệu.
\end{itemize}


%-----------------------------------------------------------------------
\section{Chuẩn hóa và tiền xử lý dữ liệu}

Dữ liệu thô sau khi thu thập từ các website 
chứa nhiều lỗi định dạng, ký tự đặc biệt, biểu 
tượng unicode, phân tách không đồng nhất và 
các trường dữ liệu khác nhau. Quá trình tiền 
xử lý sử dụng các kỹ thuật để làm sạch, 
chuẩn hóa và cấu trúc dữ liệu trước khi lưu trữ 
hoặc đưa vào pipeline RAG.

\subsection{Tổng quan quá trình tiền xử lý}

Sau khi dữ liệu thô được thu thập từ các trang 
công thức, hệ thống thực hiện một quy trình 
tiền xử lý nhằm chuẩn hóa và làm sạch dữ liệu, 
đảm bảo tính nhất quán và phù hợp cho các hệ 
thống RAG:

\begin{itemize}
    \item \textbf{Đọc và hợp nhất dữ liệu:} Tất 
    cả các tệp JSON trong file \texttt{.zip} 
    được đọc và hợp nhất, bỏ qua các tệp không 
    hợp lệ hoặc bị lỗi.
    
    \item \textbf{Chuẩn hóa văn bản:} Các trường 
    văn bản như URL, tóm tắt, nguyên liệu, 
    hướng dẫn được chuẩn hóa Unicode, loại bỏ 
    ký tự đặc biệt, khoảng trắng thừa, và các 
    biểu tượng không cần thiết. Các ký tự đặc 
    biệt và phân số Unicode được thay thế bằng 
    dạng chuẩn.
    
    \item \textbf{Chuẩn hóa dữ liệu định lượng:} 
    Các trường metadata (thời gian, khẩu phần) 
    và dinh dưỡng được chuẩn hóa về dạng số và 
    đơn vị chung (ví dụ phút, kcal). Regex và 
    các quy tắc parsing được áp dụng để tách số, 
    đơn vị và tên trường.
    
    \item \textbf{Tiền xử lý bình luận:} Các 
    bình luận được lọc để loại bỏ rỗng, spam 
    hoặc ký tự lỗi. Đồng thời, tách tác giả 
    khỏi nội dung bình luận (nếu có) và chuẩn 
    hóa văn bản, giữ lại thông tin quan trọng.
    
    \item \textbf{Chuẩn hóa cấu trúc dữ liệu:} 
    Mọi danh sách và dictionary đều được chuẩn 
    hóa, bảo đảm định dạng đồng nhất cho 
    nhúng từ và đánh chỉ số.
    
    \item \textbf{Lưu trữ dữ liệu cuối:} Dữ 
    liệu đã xử lý được hợp nhất thành một tệp 
    JSON duy nhất, sẵn sàng cho các bước 
    nhúng từ, tìm kiếm và truy vấn.
\end{itemize}

\noindent
Quy trình này đảm bảo dữ liệu thô được làm 
sạch, chuẩn hóa và chuyển về cấu trúc nhất quán, 
giảm thiểu nhiễu, đồng thời giữ lại đầy đủ thông 
tin quan trọng cho hệ thống RAG.

\subsection{Chi tiết quá trình tiền xử lý}

\subsubsection{Làm sạch dữ liệu văn bản}
\begin{itemize}
    \item Chuẩn hóa Unicode 
    để thống nhất ký tự.
    \item Thay thế các ký tự đặc biệt và ký 
    hiệu như $\degree$, ™, ®, © thành dạng chuẩn.
    \item Chuyển các phân số đặc biệt (ví dụ: 
    $\frac{1}{2}$, $\frac{1}{3}$) sang dạng 
    \texttt{1/2}, \texttt{1/3}.
    \item Loại bỏ ký tự không hiển thị, emoji, 
    whitespace thừa.
    \item Chuẩn hóa khoảng trắng và xuống dòng, 
    đảm bảo text liền mạch.
\end{itemize}

\subsubsection{Chuẩn hóa các trường dữ liệu chính}
\begin{itemize}
    \item \textbf{URL và mô tả:} loại bỏ khoảng 
    trắng thừa, chuẩn hóa text.
    \item \textbf{Nguyên liệu và hướng dẫn:} 
        \begin{itemize}
            \item Chuẩn hóa tên nguyên liệu và 
            đơn vị đo lường (g, ml, tbsp, tsp).
            \item Loại bỏ quảng cáo, watermark 
            hoặc nội dung không liên quan.
            \item Gom các bước nấu bị tách rời 
            hoặc quá ngắn thành các bước hoàn chỉnh.
        \end{itemize}
    \item \textbf{Metadata:} chuyển các thông 
    tin như thời gian nấu, số lượng phần ăn 
    thành dạng số nguyên hoặc phút; chuẩn hóa 
    tên key.
    \item \textbf{Thông tin dinh dưỡng:} chuẩn 
    hóa giá trị và đơn vị cho mỗi chất dinh 
    dưỡng, lưu thành dict \{value, unit\}.
    \item \textbf{Bình luận:} tách author và 
    nội dung bình luận, loại bỏ các chuỗi trống, 
    chuẩn hóa text.
\end{itemize}

\subsubsection{Định dạng dữ liệu theo schema chuẩn}
Dữ liệu sau khi tiền xử lý được lưu trữ theo 
cấu trúc JSON thống nhất, ví dụ:

\begin{verbatim}
{
    "URL": "...",
    "Summary": "...",
    "Ingredients": ["..."],
    "Instructions": ["..."],
    "Metadata": {
        "prep_time_minutes": 10,
        "total_time_minutes": 10,
        "servings": 2,
    },
    "Nutrition": {
        "calories": {"value": 250, "unit": "kcal"},
        "protein": {"value": 15, "unit": "g"},
        ...
    },
    "Comments": [
        {"author": "User1", "text": "..."},
        {"author": null, "text": "..."}
    ]
}
\end{verbatim}

%=======================================================================
\section{Vector Database: ChromaDB}

ChromaDB được sử dụng để lưu trữ dữ liệu với mỗi
công thức có cấu trúc như sau:

\begin{itemize}
    \item ID duy nhất cho mỗi đoạn tài liệu.
    \item Embedding của các đoạn tài liệu trong đó
    vector được sinh từ mô hình nhúng từ mặc
    định của ChromaDB \textbf{all-MiniLM-L6-v2},
    mỗi vector có độ dài 384 chiều.
    \item Nội dung văn bản (document) tóm tắt 
    các trường chính.
    \item Metadata như: nguồn, thời gian nấu, 
    dinh dưỡng.
\end{itemize}

\subsection*{Cấu trúc lưu trữ trong ChromaDB}
\begin{verbatim}
{
    "id": "recipe_001_chunk_01",
    "embedding": [...],
    "document": "Summary: ... | Ingredients: ... | Instructions: ... | Prep: ...min, Cook: ...min",
    "metadata": {
        "url": "...",
        "prep_time": 0,
        "cook_time": 0,
        "servings": 0,
        "nutr_val_{nutrient}": 0,
        "nutr_unit_{nutrient}": "...",
    }
}
\end{verbatim}

%=======================================================================
\section{Retrieval-Augmented Generation (RAG)}

\subsection{Thành phần chính}

\begin{itemize}
    \item \textbf{Embedding Generator:} tạo 
    vector cho truy vấn và tài liệu.
    \item \textbf{Retriever (ChromaDB):} tìm 
    kiếm cosine similarity.
    \item \textbf{Context Injection:} đưa các 
    đoạn liên quan vào prompt.
    \item \textbf{LLM (Gemini):} ghi nhận, phân tích
    yêu cầu người dùng và sinh phản hồi có ngữ cảnh
    (Đầu - Cuối).
\end{itemize}

\subsection{Quy trình RAG chi tiết}

\begin{enumerate}
    \item Nhận truy vấn đầu vào (đa ngôn ngữ) $Q$.
    \item Chuẩn hoá truy vấn bằng Gemini (dịch 
    sang tiếng Anh nếu cần).
    \[
        Q' = \text{Normalize}(Q)
    \]
    \item Lọc ra những từ khoá quan trọng thể hiện
    sở thích, nguyên liệu, yêu cầu dinh dưỡng hoặc
    lưu ý về tình trạng sức khỏe.
    \[
        S = \text{Translate}(\text{ExtractPreferences}(Q'))
    \]
    \item Trích xuất các từ khóa lọc thông số dinh dưỡng
    nâng cao (nếu có) từ truy vấn.
    \[
        F = \text{ExtractFilters}(Q')
    \]
    \item Sinh embedding truy vấn.
    \[
        V = \text{Embed}(Q')
    \]
    \item Thực hiện tìm kiếm ngữ nghĩa trong ChromaDB để
    chọn top-$k$ đoạn liên quan nhất sắp xếp
    \[
        D = \text{Retrieve}(V, F, k)
    \]
    theo độ tương đồng từ cao đến thấp.
    \item Ghép prompt 
    (ngữ cảnh + truy vấn người dùng).
    \[
        P = \text{ConstructPrompt}(D, Q')
    \]
    \item LLM sinh phản hồi theo tiếng Anh.
    \[
        A = \text{Gemini.generate}(P, S)
    \]
    \item Nếu ngôn ngữ đầu vào không phải 
    tiếng Anh, dịch phản hồi về ngôn ngữ gốc.
    \[
        A' = \text{Translate}(A, \text{lang}(Q))
    \]
    \item Gửi kết quả + nguồn trích dẫn về frontend.
\end{enumerate}

%=======================================================================
\subsection{Triển khai Backend}

Hệ thống backend của FoodChatbot được xây dựng 
bằng Flask, đóng vai trò cầu nối giữa giao diện 
web và pipeline xử lý RAG. Thành phần này chịu 
trách nhiệm phục vụ giao diện người dùng, tiếp 
nhận yêu cầu chat, quản lý phiên hội thoại và 
chuyển tiếp truy vấn đến mô hình chatbot.

\subsubsection{Thành phần chính}

\begin{itemize}
    \item \textbf{Web Server}: cung cấp giao diện 
    chat và các tệp tĩnh như HTML, CSS, JavaScript.
    \item \textbf{REST API}: xử lý các yêu cầu 
    từ frontend bao gồm gửi tin nhắn, reset hội 
    thoại và tải asset.
    \item \textbf{Session Manager}: duy trì ngữ 
    cảnh hội thoại riêng cho từng người dùng 
    thông qua session của Flask.
\end{itemize}

\subsubsection{Các API quan trọng}

\begin{itemize}
    \item \textbf{GET /} \\
          Trả về trang giao diện chính của 
          chatbot (\texttt{index.html}), là điểm 
          vào của ứng dụng web.

    \item \textbf{GET /home/<filename>} \\
          Trả về các tệp CSS, JavaScript và các 
          tài nguyên tĩnh cần thiết cho frontend.

    \item \textbf{POST /api/chat} \\
          Nhận tin nhắn từ người dùng, kích hoạt 
          pipeline xử lý của chatbot và trả về 
          phản hồi dạng JSON.

    \item \textbf{POST /api/reset} \\
          Xóa toàn bộ lịch sử hội thoại trong 
          session, giúp người dùng bắt đầu cuộc 
          trò chuyện mới.
\end{itemize}

\subsubsection{Luồng xử lý của \texttt{/api/chat}}

Khi người dùng gửi yêu cầu POST chứa tin nhắn, 
backend thực hiện quy trình sau:

\begin{enumerate}
    \item Backend nhận payload JSON và lấy nội 
    dung truy vấn.
    \item Truy vấn được chuyển đến chatbot để 
    xử lý.
    \item Bên trong chatbot, pipeline xử lý RAG 
    được thực thi.
    \item Backend tách phần phản hồi và danh 
    sách nguồn tham chiếu (nếu có).
    \item Trả về kết quả dưới dạng JSON: 
    \[
        \{\text{response},\ \text{sources}\}.
    \]
\end{enumerate}

\subsubsection{Luồng xử lý của \texttt{/api/reset}}

\begin{enumerate}
    \item Backend nhận yêu cầu POST từ frontend.
    \item Gọi chức năng reset trong chatbot 
    để xóa toàn bộ lịch sử hội thoại.
    \item Trả về JSON thông báo việc đặt lại 
    hội thoại thành công.
\end{enumerate}

\subsection{Triển khai Frontend}
Giao diện người dùng của FoodChatbot được xây dựng 
bằng HTML, CSS và JavaScript, cung cấp trải nghiệm 
trò chuyện trực quan và thân thiện. Người dùng có thể
gửi câu hỏi, nhận phản hồi và xem nguồn tham chiếu
một cách dễ dàng.

Giao diện chính gồm:
\begin{itemize}
    \item \textbf{Thanh tiêu đề}: hiển thị tên 
    chatbot và logo.
    \item \textbf{Khu vực hiển thị hội thoại}: 
    nơi các tin nhắn từ người dùng và chatbot 
    được trình bày theo dạng bong bóng chat.
    \item \textbf{Thanh nhập tin nhắn}: cho phép 
    người dùng nhập câu hỏi và gửi đi.
    \item \textbf{Nút reset}: để xóa lịch sử 
    hội thoại và bắt đầu cuộc trò chuyện mới.
\end{itemize}

\begin{figure}[!h]
    \centering
    \includegraphics[width=1\textwidth]{fe_chatbot.jpg}
    \caption{Giao diện người dùng của FoodChatbot.}
\end{figure}

\chapter{Kết quả và Phân tích}

Trong chương này, báo cáo trình bày kết quả đạt 
được từ quá trình xây dựng và đánh giá hệ thống 
chatbot gợi ý món ăn.

\section{Phương pháp đánh giá}

Mục tiêu của phần đánh giá là đánh giá cả về 
trải nghiệm hội thoại và độ chính 
xác nội dung của hệ thống chatbot trong hai 
kịch bản chính: (1) hội thoại nhiều lượt 
(multi-turn) và (2) trả lời một lượt (one-shot). 
Đánh giá được thiết kế sao cho kết quả vừa phản 
ánh cảm nhận người dùng vừa kiểm tra được mức 
độ chính xác của mô hình dựa trên thông tin trong
cơ sở dữ liệu.

\subsection{Tổng quan thực nghiệm}
\begin{itemize}
    \item \textbf{Số phiên (sessions)}: 
    30 phiên với multi-turn và 100 phiên với one-shot.
    \item \textbf{Kịch bản multi-turn}: mỗi 
    phiên gồm tối đa 10 lượt prompt từ người 
    đánh giá đến chatbot; đánh giá được ghi 
    lại ở mốc 2, 5 và 10 lượt.
    \item \textbf{Kịch bản one-shot}: mỗi truy 
    vấn độc lập (không có ngữ cảnh trước đó) 
    được đưa vào chatbot một lần; lặp lại 100 
    truy vấn để đánh giá tính ổn định và chính 
    xác từ lượt đầu.
    \item \textbf{Người đánh giá (raters)}: 
    các đánh giá viên là người thật (nhóm kiểm 
    thử nội bộ), thực hiện hội thoại và chấm 
    điểm theo cảm nhận cá nhân.
\end{itemize}

\subsection{Quy trình đánh giá chi tiết}
\begin{enumerate}
    \item \textbf{Chuẩn bị prompt}: Người đánh
    giá dựa trên dữ liệu thực tế đã thu thập để
    thực hiện các kịch bản hội thoại và truy vấn.
    \item \textbf{Hướng dẫn người đánh giá}: 
    cung cấp ví dụ minh hoạ, nhấn mạnh:
    \begin{itemize}
        \item Khi chấm \textit{độ thiện cảm}, 
        đánh giá viên cân nhắc tính thân thiện, 
        rõ ràng, dễ đọc và phong cách hội thoại.
        \item Khi chấm \textit{độ chính xác}, 
        chỉ xét những thông tin có thể kiểm chứng 
        trực tiếp từ cơ sở dữ liệu. Nếu chatbot đưa 
        thông tin không có trong DB hoặc trả lời
        không đúng trọng tâm thì tính 
        là không chính xác.
    \end{itemize}
    \item \textbf{Tiến hành phiên multi-turn}:
    \begin{itemize}
        \item Mỗi phiên, đánh giá viên thực hiện 
        tối đa 10 lượt prompt theo kịch bản hoặc 
        tuỳ biến (tối đa 5 truy vấn, còn lại là
        hỏi đáp).
        \item Sau lượt 2, 5, 10, đánh giá viên 
        chấm \textit{độ thiện cảm} (thang 1--10) 
        và \textit{độ chính xác tích lũy} (thang 1--10
        theo cảm nhận kết quả truy vấn đúng).
    \end{itemize}
    \item \textbf{Tiến hành kịch bản one-shot}:
    \begin{itemize}
        \item Với 100 truy vấn one-shot, hệ thống 
        trả lời một lần cho mỗi truy vấn; đánh 
        giá viên gán điểm số (thang 1--10) 
        cho từng phản hồi dựa trên 
        dữ liệu trong DB.
    \end{itemize}
\end{enumerate}

\subsection{Định nghĩa chỉ số}
\paragraph{Độ thiện cảm tích lũy (Cumulative Likability)}
\begin{itemize}
    \item Thang điểm: 1--10 
    (1 = rất khó chịu, 10 = rất thoải mái).
    \item Đánh giá dựa trên: sự tự nhiên 
    của văn phong, lịch sự và thân thiện, 
    rõ ràng trong cách trình bày.
    \item Với mỗi phiên $j$ và tại mốc $n$ lượt,
    định nghĩa:
    \[
    L_{j,n} = \text{điểm thiện cảm ở phiên } j \text{ gán sau lượt } n.
    \]
    \item Tổng hợp qua $S$ phiên, trung bình độ thiện cảm 
    tích lũy tại mốc $n$ là:
    \[
    \bar{L}_n = \frac{1}{S}\sum_{j=1}^{S} L_{j,n}.
    \]
    \item Độ lệch chuẩn của độ thiện cảm tại mốc $n$ là:
    \[
    \sigma_{L_n} = \sqrt{\frac{1}{S-1}\sum_{j=1}^{S}(L_{j,n} - \bar{L}_n)^2}.
    \]
\end{itemize}

\paragraph{Độ chính xác tích lũy (Cumulative accuracy)}
\begin{itemize}
    \item Thang điểm: 1--10 
    (1 = sai hoàn toàn, 10 = chính xác tuyệt đối).
    \item Đánh giá dựa trên: độ chính xác của thông
    tin trả lời so với dữ liệu trong cơ sở dữ liệu.
    Đồng thời xét đến yếu tố đầy đủ, trọng tâm 
    và không bịa đặt. Khả năng suy luận (cho phép
    vượt ra ngoài phạm vi cơ sở dữ liệu nhẹ) để 
    tạo ra thông tin
    phù hợp với cá nhân người dùng cũng được xét đến. 
    \item Với mỗi phiên $j$ và tại mốc $n$ lượt, 
    định nghĩa:
    \[
    \text{acc}_{j,n} = \frac{\text{Tổng số câu trả lời đúng trong các lượt }1..n}{n}.
    \]
    \item Tổng hợp qua $S$ phiên, trung bình độ chính xác 
    tích lũy tại mốc $n$ là:
    \[
    \text{Acc}_n = \frac{1}{S}\sum_{j=1}^{S} \text{acc}_{j,n}.
    \]
    \item Độ lệch chuẩn của độ chính xác tại mốc $n$ là:
    \[
    \sigma_{\text{Acc}_n} = \sqrt{\frac{1}{S-1}\sum_{j=1}^{S}(\text{acc}_{j,n} - \text{Acc}_n)^2}.
    \]
    \item Trong đó, "câu trả lời đúng" được hiểu là: nội 
    dung trả lời khớp (hoặc bao gồm) thông tin 
    xác thực có trong cơ sở dữ liệu; đối với câu hỏi yêu 
    cầu gợi ý danh sách, mỗi item gợi ý được 
    kiểm tra riêng. Và "câu trả lời sai" được hiểu là
    nội dung không có trong DB, sai trọng tâm
    yêu cầu, bịa đặt thông tin, hoặc suy luận sai
    dẫn đến cung cấp thông tin không hợp lý, gây hại
    cho người dùng.
\end{itemize}

\paragraph{Độ chính xác one-shot}
\begin{itemize}
    \item Với $M=100$ truy vấn độc lập, mỗi truy 
    vấn $i$ được đánh giá độ chính xác dựa trên
    thang điểm 1--10.  
    \[
    \text{OneShotAcc} = \frac{1}{M}\sum_{i=1}^{M} c_i.
    \]
    \item Độ lệch chuẩn của độ chính xác one-shot là:
    \[
    \sigma_{\text{OneShotAcc}} = \sqrt{\frac{1}{M-1}\sum_{i=1}^{M}(c_i - \text{OneShotAcc})^2}.
    \]
    \item Quy tắc quyết định đúng/sai tương tự như trên.
\end{itemize}

\section{Kết quả}

\noindent Dựa trên 30 phiên multi-turn và 100 truy vấn one-shot, thu được:

\begin{itemize}
    \item \textbf{Độ thiện cảm và độ chính xác 
    tích lũy theo mốc hội thoại theo multi-turn}:
\begin{table}[H]
\centering
\caption{Kết quả đánh giá theo từng mốc hội thoại}
\begin{tabular}{|c|cc|cc|}
\hline
\textbf{Mốc} & 
\multicolumn{2}{c|}{\textbf{Độ thiện cảm}} & 
\multicolumn{2}{c|}{\textbf{Độ chính xác}} \\ \hline
 & $\bar{L}_n$ & $\sigma_{L_n}$ & $\text{Acc}_n$ & $\sigma_{\text{Acc}_n}$ \\ \hline
2  & 8.7667 & 0.3278 & 8.6583 & 0.6581 \\ \hline
5 & 8.6917 & 0.2516 & 8.1833 & 0.4777 \\ \hline
10 & 9.0167 & 0.2702 & 8.5667 & 0.3212 \\ \hline
\end{tabular}
\label{tab:multi-turn-eval-detail}
\end{table}

    \item \textbf{Độ chính xác one-shot}:  
    \[
    \text{OneShotAcc} = 7.6825
    \]
    \[
    \sigma_{\text{OneShotAcc}} = 0.7478
    \]
\end{itemize}

\subsection*{Phân tích chi tiết kết quả}

\paragraph{1. Xu hướng thay đổi theo số lượt hội 
thoại}

Dựa trên kết quả ở \ref{tab:multi-turn-eval-detail}, 
có thể nhận thấy hai xu hướng khác biệt giữa hai 
chỉ số đánh giá:

\begin{itemize}
    \item \textbf{Độ thiện cảm} ($\bar{L}_n$) 
    tăng đều qua các mốc, từ 8.7667 ở mốc 2 lên 
    8.6917 ở mốc 5 và đạt 9.0167 ở mốc 10.  
    Điều này cho thấy khi hội thoại kéo dài, 
    chatbot tạo ra cảm giác tự nhiên và thân
     thiện hơn với người dùng. Lượng ngữ cảnh 
     tích lũy giúp hệ thống duy trì phong cách 
     trả lời ổn định và phù hợp với kỳ vọng 
     của người dùng.

    \item \textbf{Độ chính xác} ($\text{Acc}_n$) 
    lại thể hiện xu hướng không tăng tuyến tính:  
    \[
    8.6583\ (\text{mốc 2}) \rightarrow 8.1833\ (\text{mốc 5}) \rightarrow 8.5667\ (\text{mốc 10})
    \]
    Kết quả này cho thấy độ chính xác 
    giảm rõ rệt tại mốc 5 nhưng tăng trở lại ở 
    mốc 10, dù vẫn chưa bằng mức ban đầu (mốc 2).  
    Xu hướng dao động này phản ánh rằng hiệu 
    quả truy vấn của hệ thống phụ thuộc mạnh 
    vào chất lượng và mức độ rõ ràng của ngữ 
    cảnh hội thoại.
\end{itemize}

\paragraph{Giải thích chi tiết cho xu hướng này}

\begin{itemize}
    \item \textbf{Ngữ cảnh phức tạp có thể gây 
    nhiễu retrieval}:  
    Khi số lượt hội thoại tăng, người dùng có 
    xu hướng mô tả dài hơn, chứa nhiều tham 
    chiếu hoặc điều kiện ràng buộc.  
    Tại mốc 5, lượng ngữ cảnh chưa đủ ổn định 
    nhưng lại đủ dài để tạo nhiễu, khiến module 
    rewrite và retrieval hoạt động kém tối ưu.

    \item \textbf{Hiệu ứng tích lũy ngữ cảnh ở 
    mốc 10}:  
    Tại mốc 10, thông tin đã được ổn định và làm 
    rõ. Chatbot có thể sử dụng ngữ cảnh để rút 
    ra mục đích người dùng chính xác hơn, nhờ 
    đó điểm chính xác tăng trở lại.

    \item \textbf{Độ thiện cảm tăng nhờ khả năng 
    thích ứng phong cách hội thoại}:  
    Các mô hình LLM thường tối ưu tốt trong việc 
    duy trì phong cách giao tiếp nhất quán. 
    Khi lượng ngữ cảnh tăng, mô hình có thể tạo 
    ra các câu trả lời tự nhiên, mềm mại và phù 
    hợp hơn với phong cách người dùng, dẫn đến 
    điểm thiện cảm tăng đều.

    \item \textbf{Dữ liệu và cấu trúc DB giới 
    hạn độ chính xác tuyệt đối}:  
    Nếu người dùng yêu cầu các thông tin không 
    có sẵn trong DB hoặc đặt câu hỏi với cấu 
    trúc không điển hình, độ chính xác sẽ bị 
    giảm. Điều này ảnh hưởng rõ nhất ở mốc 5.
\end{itemize}

\paragraph{2. So sánh One-shot và Multi-turn}

One-shot accuracy được ghi nhận là:
\[
\text{OneShotAcc} = 7.6825, \qquad \sigma_{\text{OneShotAcc}} = 0.7478
\]

Kết quả này thấp hơn toàn bộ các mốc multi-turn, 
bao gồm cả mốc thấp nhất (mốc 5).  
Điều này có thể giải thích bởi:

\begin{itemize}
    \item \textbf{Thiếu ngữ cảnh}: one-shot yêu 
    cầu hệ thống phải hiểu đúng ý ngay lập tức, 
    trong khi nhiều truy vấn tự nhiên của người 
    dùng cần được làm rõ hoặc viết lại qua vài 
    lượt.
    \item \textbf{Khó giải quyết các tham chiếu 
    mơ hồ}: các truy vấn kiểu "món đó", "cách 
    làm kia" không thể được xác định trong 
    one-shot.
    \item \textbf{Semantic search không có hỗ 
    trợ từ rewrite hay history}: điểm truy vấn 
    embedding kém dẫn đến retrieval không chính 
    xác.
\end{itemize}

\paragraph{3. Phân tích lỗi (Error Analysis)}

Dựa trên quan sát của 100 phiên thử nghiệm, 
các lỗi xuất hiện có thể được phân loại thành 
các nhóm:

\begin{enumerate}
    \item \textbf{Thiếu không tin}:  
    DB không chứa trường thông tin mà người 
    dùng yêu cầu (ví dụ: nutrition details, 
    time breakdown), dẫn đến việc chatbot trả 
    lời thiếu hoặc không trả lời được.

    \item \textbf{Dịch sai / không sát nghĩa}:  
    Quá trình dịch (nếu có) — từ tiếng Việt sang 
    tiếng Anh để phục vụ retrieval — đôi khi 
    làm mất sắc thái ý nghĩa, gây sai truy vấn.

    \item \textbf{Giải thích filter sai}:  
    Module sinh filter 
    (generate\_chromadb\_filter) đôi khi tạo 
    cú pháp sai hoặc hiểu nhầm ý, dẫn 
    đến trả về sai các món cần lọc.

    \item \textbf{Trả lời không đầy đủ}:  
    Chatbot chỉ trả lời một phần — thường 
    gặp khi yêu cầu liệt kê danh sách dài 
    (step-by-step recipe, tất cả nguyên liệu, 
    toàn bộ công thức).

    \item \textbf{Ảo giác (ít gặp)}:  
    Khi ngữ cảnh không đủ rõ ràng hoặc retrieval 
    không mang lại tài liệu phù hợp, mô hình 
    có thể tự điền thêm thông tin ngoài DB. 
    Tuy nhiên, tần suất thấp nhờ prompt thiết 
    kế chặt chẽ.
\end{enumerate}

\section{Đánh giá kết quả}

\subsection{Khả năng hiểu và xử lý đa ngôn ngữ}

Hệ thống chatbot đã hỗ trợ thành công tương tác 
bằng nhiều ngôn ngữ, bao gồm tiếng Việt, tiếng 
Anh và một số ngôn ngữ phổ biến khác. Điều này 
có được nhờ việc sử dụng mô hình ngôn ngữ đa 
ngôn ngữ trong pipeline xử lý ngôn ngữ tự nhiên. 
Chatbot có thể:

\begin{itemize}
    \item Hiểu yêu cầu của người dùng trong nhiều 
    ngôn ngữ khác nhau.
    \item Chuyển đổi yêu cầu thành dạng tiêu 
    chuẩn hoá để tìm kiếm trong cơ sở dữ liệu.
    \item Trả lời bằng đúng ngôn ngữ mà người 
    dùng đang sử dụng.
\end{itemize}

\subsection{Khả năng gợi ý món ăn dựa trên yêu cầu}

Hệ thống có thể phân tích yêu cầu mô tả món ăn 
hoặc bối cảnh do người dùng đưa ra (ví dụ: “tôi 
muốn một món ít béo”, “món phù hợp cho trẻ em”, 
“món ăn nhẹ buổi tối”). Từ đó chatbot thực hiện:

\begin{itemize}
    \item Truy xuất các món ăn trong cơ sở dữ liệu.
    \item So khớp chúng với tiêu chí được suy 
    luận từ ngữ nghĩa yêu cầu người dùng.
    \item Gợi ý một hoặc nhiều món ăn phù hợp 
    nhất.
\end{itemize}

Nhờ đó, chatbot không chỉ đóng vai trò trả lời 
câu hỏi mà còn hoạt động như một trợ lý ẩm thực 
có khả năng phân tích bối cảnh.

\subsection{Phân tích yêu cầu dinh dưỡng và sức khỏe}

Hệ thống cũng được trang bị khả năng phân tích 
yêu cầu về sức khỏe và dinh dưỡng, bao gồm:

\begin{itemize}
    \item Bóc tách các chỉ số dinh dưỡng mà 
    người dùng quan tâm như calories, protein, 
    fat, carbs,...
    \item Hiểu các yêu cầu liên quan đến tình 
    trạng sức khỏe như: bệnh tiểu đường, dị ứng, 
    chế độ ăn kiêng (low-carb, high-protein, 
    gluten-free), hoặc các mục tiêu như tăng 
    cơ/giảm cân.
    \item Kết hợp dữ liệu thực tế trong công 
    thức món ăn để đưa ra danh sách món ăn phù 
    hợp với tình trạng hoặc mục tiêu sức khỏe 
    của người dùng.
\end{itemize}

\subsection{Ưu điểm của hệ thống}

Hệ thống chatbot ẩm thực được xây dựng trên 
nền tảng RAG và tích hợp LLM mang lại nhiều ưu 
điểm nổi bật, thể hiện qua khả năng tương tác, 
chất lượng gợi ý và mức độ cá nhân hoá. Cụ thể:

\begin{itemize}
    \item \textbf{Khả năng tương tác tự nhiên và thân thiện}:  
    Chatbot duy trì phong cách hội thoại linh 
    hoạt, dễ thích nghi với giọng điệu và cách 
    đặt câu hỏi của người dùng, tạo cảm giác 
    trò chuyện liền mạch và dễ tiếp cận.

    \item \textbf{Phân tích tốt các yêu cầu phức tạp}:  
    Nhờ sức mạnh của mô hình ngôn ngữ lớn (LLM), 
    chatbot có thể hiểu và phân tách các yêu 
    cầu nhiều thành phần như:  
    “Gợi ý món không chứa gluten, ít đường, 
    phù hợp cho người tiểu đường và có nguyên 
    liệu dễ mua”.

    \item \textbf{Giảm thiểu hiện tượng ảo giác}:  
    Việc kết hợp RAG giúp mô hình chỉ sử dụng 
    thông tin lấy từ cơ sở dữ liệu món ăn đã 
    được chuẩn hoá, tránh các câu trả lời bịa 
    đặt hoặc không có nguồn.

    \item \textbf{Đảm bảo độ chính xác cao}:  
    Toàn bộ gợi ý được sinh ra từ dữ liệu thu 
    thập thực tế, giúp mô hình trả lời đúng 
    theo công thức, nguyên liệu và hướng dẫn 
    nấu ăn có thật.

    \item \textbf{Lưu trữ và khai thác sở thích người dùng để tăng tính cá nhân hoá}:  
    Hệ thống có thể ghi nhớ một số ngữ cảnh 
    và sở thích từ phiên trò chuyện (ví dụ: 
    món ăn yêu thích, sở thích ăn cay nhẹ, khẩu 
    phần nhỏ, yêu cầu về ăn kiêng).  
    Điều này cho phép chatbot đưa ra các gợi ý 
    phù hợp hơn trong các lượt trò chuyện tiếp 
    theo, nâng cao trải nghiệm cá nhân hoá.

    \item \textbf{Nhận diện yêu cầu chuyên sâu về dinh dưỡng}:  
    Chatbot có thể phân tích các ràng buộc về 
    sức khoẻ hoặc nhu cầu dinh dưỡng như:  
    \begin{itemize}
        \item ít calo, ít carb, giàu protein  
        \item tránh chất béo bão hoà  
        \item phù hợp cho người tiểu đường hoặc 
        người ăn kiêng Keto  
    \end{itemize}
    Qua đó hệ thống có thể lọc và lựa chọn món 
    ăn phù hợp từ cơ sở dữ liệu.

    \item \textbf{Nhận diện và loại bỏ các thành phần cần tránh}:  
    Chatbot có thể hiểu các yêu cầu liên quan 
    đến dị ứng hoặc kiêng khem (như tránh sữa, 
    gluten, hải sản, đậu phộng) và tự động loại 
    bỏ các món chứa thành phần không phù hợp.
\end{itemize}

\subsection{Hạn chế của hệ thống}

Mặc dù đạt hiệu quả tốt, hệ thống vẫn tồn tại 
một số hạn chế như sau:

\begin{itemize}
    \item \textbf{Hạn chế về dữ liệu}:  
    Cơ sở dữ liệu món ăn còn tương đối nhỏ, 
    chủ yếu thu thập từ một nguồn duy nhất. 
    Điều này dẫn đến phạm vi gợi ý hạn chế 
    và chưa có sự phong phú về văn hoá ẩm thực 
    trên thế giới.

    \item \textbf{Thiếu đa dạng về danh mục ẩm thực}:  
    Chưa bao phủ đầy đủ các món ăn đến từ nhiều 
    nền ẩm thực khác nhau. Điều này hạn chế 
    khả năng đáp ứng yêu cầu đa dạng của người dùng.

    \item \textbf{Thiếu dữ liệu dinh dưỡng hoàn chỉnh}:  
    Một số công thức món ăn không có đủ thông 
    tin chi tiết về dinh dưỡng (ví dụ: lượng 
    vitamin, khoáng chất, thành phần vi chất), 
    khiến chatbot chưa thể đáp ứng tốt các yêu 
    cầu chuyên sâu về sức khỏe.

    \item \textbf{Hạn chế do sử dụng API Gemini miễn phí}:  
    Việc sử dụng phiên bản miễn phí của API 
    Gemini khiến tốc độ phản hồi đôi khi chậm, 
    đặc biệt trong các phiên trò chuyện nhiều lượt. Điều này ảnh hưởng đến trải nghiệm người dùng và giới hạn tần suất truy vấn liên tục.

    \item \textbf{Chất lượng dịch sang tiếng Anh chưa tối ưu}:  
    Do mô hình sử dụng bước chuyển đổi truy 
    vấn sang tiếng Anh trước khi truy xuất dữ 
    liệu, một số yêu cầu phức tạp hoặc ngữ 
    cảnh đặc thù bị dịch không sát nghĩa. Hậu 
    quả là hệ thống truy xuất sai hoặc thiếu 
    tài liệu cần thiết, dẫn đến kết quả phản 
    hồi chưa thật sự chính xác.

    \item \textbf{Phụ thuộc mạnh vào cơ sở dữ liệu}:  
    Vì hệ thống được thiết kế để hạn chế ảo 
    giác, mọi phản hồi đều dựa vào dữ liệu đã 
    có. Nếu dữ liệu bị thiếu, sai hoặc không 
    khớp ngữ cảnh, chatbot sẽ không thể bù 
    trừ bằng khả năng suy luận của mô hình 
    ngôn ngữ lớn, dẫn đến các trường hợp hệ 
    thống trả lời “thiếu thông tin”.
\end{itemize}

% Chương 4: Kết luận
\chapter{Kết luận}

Trong báo cáo này, hệ thống chatbot gợi ý món ăn 
đã được xây dựng dựa trên kiến trúc 
Retrieval-Augmented Generation (RAG) kết hợp với 
mô hình ngôn ngữ lớn (LLM), cho phép hiểu yêu 
cầu người dùng, truy xuất dữ liệu công thức 
món ăn và sinh câu trả lời tự nhiên theo văn 
phong hội thoại. Tập dữ liệu được thu thập và 
chuẩn hoá từ nguồn \texttt{therecipecritic.com}, 
sau đó chuyển thành không gian nhúng 
(embedding space) để thực hiện tìm kiếm ngữ 
nghĩa hiệu quả.

Kết quả thực nghiệm cho thấy hệ thống đạt chất 
lượng tốt, đặc biệt trong bối cảnh hội thoại 
nhiều lượt. Độ thiện cảm (likability) tăng dần 
khi số lượt hội thoại tăng, phản ánh khả năng 
thích nghi ngữ cảnh và phong cách trò chuyện 
của mô hình. Độ chính xác tích lũy của các câu 
trả lời cũng tăng đáng kể, nhờ cơ chế lưu trữ 
ngữ cảnh và khai thác thông tin đã được tích 
luỹ trong phiên hội thoại. Ngoài ra, hệ thống 
thể hiện khả năng phân tích yêu cầu phức tạp 
về dinh dưỡng, sức khỏe, các thành phần cần 
tránh (allergens), và hỗ trợ người dùng bằng 
nhiều ngôn ngữ.

Mặc dù vậy, hệ thống vẫn tồn tại một số hạn chế 
như quy mô dữ liệu nhỏ, tính đa dạng ẩm thực 
còn thấp, thiếu thông tin dinh dưỡng đầy đủ cho 
nhiều món, và sự phụ thuộc vào phiên bản miễn 
phí của API Gemini làm giảm tốc độ và đôi khi 
gây lỗi dịch không sát nghĩa. Điều này dẫn đến 
một số truy vấn bị diễn giải sai, gây ảnh hưởng 
đến quá trình truy xuất và gợi ý.

Dựa trên kết quả đạt được, một số hướng phát 
triển khả thi bao gồm:

\begin{itemize}
    \item \textbf{Mở rộng và đa dạng hóa cơ sở 
    dữ liệu món ăn}: bổ sung dữ liệu từ nhiều 
    nền ẩm thực khác nhau (Á, Âu, Nam Á, Trung 
    Đông) để tăng khả năng gợi ý đa dạng hơn, 
    đáp ứng các thị trường người dùng khác nhau.
    \item \textbf{Bổ sung dữ liệu dinh dưỡng 
    chuyên sâu}: thêm các chỉ số quan trọng như 
    vitamin, khoáng chất, chỉ số đường huyết (GI), 
    thành phần vi chất để hỗ trợ các trường hợp 
    yêu cầu phức tạp về sức khỏe.
    \item \textbf{Nâng cấp mô-đun dịch và chuẩn 
    hóa truy vấn}: giảm thiểu lỗi chuyển đổi 
    ngôn ngữ bằng cách sử dụng mô hình 
    dịch chuyên dụng để cải thiện độ chính 
    xác truy vấn.
    \item \textbf{Tăng cường cá nhân hóa}: lưu 
    trữ sở thích dài hạn của người dùng (ví dụ 
    mức độ cay, chế độ ăn, dị ứng, khẩu phần) 
    ngay cả khi thay đổi phiên hội thoại; từ 
    đó xây dựng hệ thống gợi ý món ăn mang tính 
    cá nhân hóa sâu hơn.
    \item \textbf{Tối ưu hóa tốc độ}: chuyển sang 
    sử dụng phiên bản API trả phí hoặc mô hình 
    open-source chạy cục bộ nhằm khắc phục giới 
    hạn tốc độ và tránh tình trạng tắc nghẽn 
    truy vấn.
    \item \textbf{Tự động phân tích lỗi 
    (self-evaluation)}: áp dụng các chỉ số như 
    Precision@k, Recall@k hoặc nDCG@k để đánh 
    giá chất lượng retrieval một cách định 
    lượng và liên tục cải thiện pipeline.
    \item \textbf{Xây dựng giao diện người dùng 
    hoàn chỉnh}: tích hợp chatbot vào ứng dụng 
    web/mobile giúp người dùng dễ dàng truy cập 
    và tương tác, mở rộng hệ thống từ dạng thử 
    nghiệm sang sản phẩm thực tế.
\end{itemize}

Tổng thể, hệ thống chatbot gợi ý món ăn đã chứng 
minh tính khả thi và hiệu quả trong việc kết 
hợp RAG, cơ sở dữ liệu món ăn và mô hình LLM. 
Các kết quả đạt được cho thấy tiềm năng phát 
triển thành một công cụ hỗ trợ dinh dưỡng và 
ẩm thực thông minh, có khả năng phục vụ tốt 
trong nhiều bối cảnh ứng dụng thực tế như tư 
vấn thực đơn, gợi ý dinh dưỡng, hỗ trợ người 
ăn kiêng hoặc người có yêu cầu sức khỏe đặc biệt.

% % Tài liệu tham khảo
% \chapter*{Tài liệu tham khảo}
\addcontentsline{toc}{chapter}{Tài liệu tham khảo}
% Sử dụng BibTeX hoặc môi trường thebibliography nếu cần
\begin{thebibliography}{9}
\bibitem{transformer} Vaswani Ashish, ``Attention Is All You Need,'' \doi{10.48550/arXiv.1706.03762}
\bibitem{self_attention} The ML Tech Lead!, ``Understanding the Self-Attention Mechanism in 8 min'', \url{www.youtube.com/watch?v=W28LfOld44Y}
\bibitem{multihead_attention} The ML Tech Lead!, ``The Multi-head Attention Mechanism Explained!'', \url{www.youtube.com/watch?v=W6s9i02EiR0&t=34s}
\bibitem{nlp_book} Dan Jurafsky and James H. Martin, ``Speech and Language Processing,'' 3rd Edition, Draft, 2023. \url{https://web.stanford.edu/~jurafsky/slp3/}
\bibitem{gemini_1.5} Google Research, ``Gemini 1.5 Technical Report,'' \doi{10.48550/arXiv.2403.05530}
\bibitem{gemini_2.5} Google Research, ``Gemini 2.5 Technical Report,'' \doi{10.48550/arXiv.2507.06261}
\bibitem{gqa} Google Research, ``GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints,'' \doi{10.48550/arXiv.2305.13245}
\bibitem{moe} Omar Sanseviero, Lewis Tunstall, Philipp Schmid,
Sourab Mangrulkar, Younes Belkada and Pedro Cuenca, ``Mixture of Experts Explained,'' \url{https://huggingface.co/blog/moe}
\end{thebibliography}

% Phụ lục (Tùy chọn)
\appendix
\chapter{Phụ lục}
Để chạy các chương trình, cần thực hiện các bước sau:
\section{Cài đặt môi trường}
\begin{itemize}
    \item Cài đặt Python 3.10 trở lên.
    \item Tạo môi trường ảo (virtual environment):
    \begin{verbatim}
python -m venv venv

source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
    \end{verbatim}
    \item Cài đặt các thư viện cần thiết:
    \begin{verbatim}
pip install -r requirements.txt
    \end{verbatim}
\end{itemize}
\section{Chạy chương trình}
\subsection{Khai thác dữ liệu}
\begin{verbatim}
cd crawler

# Thu thập Liên kết Danh mục
python crawl_category_links.py

# Thu thập Liên kết Công thức từ Danh mục
python crawl_recipe_links_parallel.py

# Thu thập Thông tin Công thức
python crawl_recipe_infos_parallel.py

cd ..
\end{verbatim}

\subsection{Tiền xử lý dữ liệu}
\begin{verbatim}
cd preprocessing

python food_preprocessing.py

cd ..
\end{verbatim}

\subsection{Chạy chatbot}
\begin{verbatim}
cd bot

python main.py
\end{verbatim}
\end{document}
